{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8532bfaf",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ac4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "#pd.set_option('max_colwidth', None)\n",
    "\n",
    "from platform import python_version\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from unidecode import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "\n",
    "#Linear models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import confusion_matrix, recall_score, f1_score, precision_score\n",
    "from sklearn import metrics\n",
    "\n",
    "#Text do vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "seed = np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dacf22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.8.8\n",
      "pandas 2.0.1\n",
      "numpy 1.23.5\n",
      "matplotlib 3.3.4\n",
      "sklearn 1.3.0\n"
     ]
    }
   ],
   "source": [
    "print('python',python_version())\n",
    "print('pandas',pd.__version__)\n",
    "print('numpy',np.__version__)\n",
    "print('matplotlib', matplotlib.__version__)\n",
    "print('sklearn', sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439626a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_multiclass = LabelEncoder()\n",
    "lbl_binary = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e5ccf",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c642ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(arquivo, print_head=False):\n",
    "    \n",
    "    #Read the XLSX file\n",
    "    df = pd.read_excel(arquivo)\n",
    "\n",
    "    # Add the new column 'description' with the same content of 'expense_descriprion'\n",
    "    # to preserve original data\n",
    "    df['description'] = df.expense_description.apply(str)\n",
    "\n",
    "    #Remove special characteres\n",
    "    df['description'] = df.description.apply(unidecode)\n",
    "    \n",
    "    # Add a new column with expense_class_by_expert content\n",
    "    df['class'] = df['expense_class_by_expert']\n",
    "\n",
    "    df['y_class'] = lbl_multiclass.fit_transform(df['expense_class_by_expert'])\n",
    " \n",
    "    df['binary_class'] = df.expense_class_by_expert.map({'CRED':'N', 'N':'N', 'PA_PIP':'Y', 'AJ':'Y', 'AC':'Y'})\n",
    "    df['y_binary_class'] = lbl_binary.fit_transform(df['binary_class'])\n",
    "    \n",
    "    if(print_head):\n",
    "        print(df.head(3))\n",
    "    return df\n",
    "\n",
    "def words_frequency(df, attribute, showSummary=False):\n",
    "    words_by_line = df[attribute].apply(lambda x: ' '.join(wordpunct_tokenize(x)))\n",
    "\n",
    "    text = \" \".join(words_by_line.tolist())\n",
    "    text_split = text.split()\n",
    "\n",
    "    words_amount = Counter(text_split)\n",
    "    words_frequency = list(words_amount.items())\n",
    "\n",
    "    df_words_frequency = pd.DataFrame(words_frequency, columns=['Word', 'Frequency'])\n",
    "    df_words_frequency['Length'] = df_words_frequency.Word.str.len()\n",
    "    \n",
    "    if showSummary:\n",
    "        print(df_words_frequency.describe())\n",
    "    \n",
    "    return df_words_frequency\n",
    "\n",
    "def words_distribution(df, attribute):\n",
    "    all_words = [word for tokens in df[attribute].str.split() for word in tokens]\n",
    "    sentence_lengths = [len(tokens) for tokens in df[attribute].str.strip()]\n",
    "    VOCAB = sorted(list(set(all_words)))\n",
    "\n",
    "    print(\"Total words: %s\" % (len(all_words)))\n",
    "    print(\"Single words: %s\" % (len(VOCAB)))\n",
    "    print(\"Short Description: %s\" % min(sentence_lengths))\n",
    "    print(\"Large Description: %s\" % max(sentence_lengths))\n",
    "    print(\"Mean Description: %s\" % np.mean(sentence_lengths))\n",
    "    print(\"Standard Deviation: %s\" % np.std(sentence_lengths))\n",
    "    \n",
    "def words_scatter(df):\n",
    "    f = plt.figure(figsize=(20, 7)) \n",
    "    plt.xlabel('Sequence')\n",
    "    plt.ylabel('Amount')\n",
    "    plt.scatter(df.index, df.Frequency, marker=\".\",c='green')\n",
    "    plt.show()\n",
    "\n",
    "def remove_no_letters(df, attribute):\n",
    "    df[attribute] = df[attribute].str.lower()\n",
    "    df[attribute] = df[attribute].str.replace(r\"[0-9]\", \" \")\n",
    "    df[attribute] = df[attribute].str.replace(r\"[^A-Za-z]\", \" \")\n",
    "    return df\n",
    "\n",
    "def load_stopwords():\n",
    "    \n",
    "    #stopwords from nltk\n",
    "    stop_words = list(map(unidecode, stopwords.words(\"portuguese\")))\n",
    "    \n",
    "    #municipalities names \n",
    "    municipios = pd.read_csv(\"municipios.csv\", sep=\"|\").municipio.tolist()\n",
    "    nomes = ' '.join([i for i in municipios])\n",
    "    stop_words.extend(set(nomes.split()))\n",
    "    \n",
    "    # there is a city called 'professor'\n",
    "    # So, the word professor was removed from stop word because means teacher in portuguese\n",
    "    stop_words.remove(\"professor\")\n",
    "    \n",
    "    #manually inserted words\n",
    "    stop_words.extend(['secretaria', 'municipio', 'municipal', 'goias', 'departamento', 'prefeitura', 'empenho'])\n",
    "    stop_words.extend(['empenha', 'valor', 'referente', 'ref', 'janeiro', 'mes', 'atender', 'despesa', 'ocorrer'])\n",
    "    stop_words.extend(['conforme', 'anexo', 'emitido', 'nan','primeiro', 'segundo', 'terceiro', 'termo'])\n",
    "    stop_words.extend(['aditivo','deste', 'desta'])\n",
    "    \n",
    "    return list(set(stop_words))\n",
    "\n",
    "def load_less_frequent_words(df, min_ocorrencies = 10):\n",
    "    text = \" \".join(df.tolist())\n",
    "    words_amount = Counter(text.split())\n",
    "    words_frequency = list(words_amount.items())\n",
    "    df_words = pd.DataFrame(words_frequency, columns=['Word', 'Length'])\n",
    "    \n",
    "    return list(df_words[df_words.Length <=min_ocorrencies].Word)\n",
    "\n",
    "#Cleaning the data\n",
    "def data_cleaning(df, attribute, remove_stop_words=True, minimal_occurrence=None, \n",
    "            minimal_characters=None, to_stemmer = None):\n",
    "    \n",
    "    #Remove all no letters from data text attribute\n",
    "    df = remove_no_letters(df, attribute)\n",
    "\n",
    "    #Remove stopwords\n",
    "    stop_words = load_stopwords()\n",
    "    df[attribute] = df[attribute].apply(lambda x: ' '.join([word.strip() for word in x.split() \n",
    "                                                                              if word not in (stop_words)]))\n",
    "\n",
    "    #Stemmer\n",
    "    if(to_stemmer != None):\n",
    "        print('Stemmer')\n",
    "        stemmer = SnowballStemmer(\"portuguese\")\n",
    "        df[attribute] = df[attribute].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split(\" \")]))\n",
    "    \n",
    "    \n",
    "    #Remove low frequency word\n",
    "    if(minimal_occurrence != None):\n",
    "        print('Minimal occurrence: ', minimal_occurrence)\n",
    "        low_frequency_words = load_less_frequent_words(df[attribute], min_ocorrencies=minimal_occurrence)\n",
    "        print(len(low_frequency_words))\n",
    "        \n",
    "        df[attribute] = df[attribute].apply(lambda x: ' '.join([word.strip() for word in x.split() \n",
    "                                                                              if word not in (low_frequency_words)]))\n",
    " \n",
    "    #Remove words with less than minimum characters\n",
    "    if(minimal_characters):\n",
    "        print('Minimal characters', minimal_characters)\n",
    "        df[attribute] = df[attribute].apply(lambda x: ' '.join([word.strip() for word in x.split() \n",
    "                                                                if len(word.strip()) >= minimal_characters]))\n",
    "\n",
    "    #Remove null and duplicates rows\n",
    "    print('All dataset: ', df.shape)\n",
    "    df[attribute] = df[attribute].str.strip()\n",
    "    df.drop_duplicates(inplace=True, subset=attribute, keep='first')\n",
    "    print('After removing duplicates: ', df.shape)\n",
    "    df.drop(labels=(df.loc[df[attribute] ==''].index), inplace=True)\n",
    "    print('After discarding no letters rows', df.shape)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def split_data(df, label, k=10, seed=0):\n",
    "    print('Splitint the dataset into k =', k)\n",
    "    #df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    #return np.array_split(df, k)\n",
    "\n",
    "    response = list()\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for __, test_index in skf.split(df, df[label]):\n",
    "        response.append(df.loc[test_index])\n",
    "    \n",
    "    return response\n",
    "\n",
    "def print_amount_by_fold(groups):\n",
    "    print('\\nSamples by Fold\\n')\n",
    "    \n",
    "    counter = 1\n",
    "    for i in groups:\n",
    "        print('Fold:', counter,'-', len(i))\n",
    "        counter = counter + 1\n",
    "    print('\\n\\n')\n",
    "\n",
    "def print_sample_distribution(groups, attribute):\n",
    "    print('\\nDistribution by Fold\\n')\n",
    "    \n",
    "    counter = 1\n",
    "    for i in groups:\n",
    "        print('Fold:', counter)\n",
    "        df = pd.DataFrame(i)\n",
    "        print(round(df[attribute].value_counts()), '\\n')\n",
    "        counter = counter + 1\n",
    "    print('\\n\\n')\n",
    "    \n",
    "def prediction(model, folds, class_attribute, sparse_matrix=True, lbl_encoder=None, verbose=False):\n",
    "    \n",
    "    if((verbose) & (lbl_encoder==None)):\n",
    "        print('Verbose mode demands a label encoder')\n",
    "        return \n",
    "    \n",
    "    folds_return = list()\n",
    "    \n",
    "    k = len(folds)\n",
    "    \n",
    "    if (verbose):\n",
    "        print('Model:', model, 'Class attribute:', class_attribute)\n",
    "\n",
    "    for k_i in range(0, k):\n",
    "        if (verbose):\n",
    "            print('Iteration #:',k_i+1,'\\n\\n') \n",
    "        \n",
    "        folds_copy = folds.copy()\n",
    "        \n",
    "        # k_i index is test set\n",
    "        f_test = folds_copy.pop(k_i)\n",
    "\n",
    "        #other slices are train set\n",
    "        f_train = pd.concat(folds_copy)\n",
    "            \n",
    "        #TFIDF Vectorizer instance\n",
    "        vectorizer = TfidfVectorizer()\n",
    "\n",
    "        # Use the train set to traning the tfidf vectorizer\n",
    "        f_train_vet = vectorizer.fit_transform(f_train.description)\n",
    "        f_test_vet = vectorizer.transform(f_test.description)\n",
    "        \n",
    "        if(not(sparse_matrix) or (str(model).startswith('GaussianNB')) ):\n",
    "            f_train_vet = f_train_vet.toarray()\n",
    "            f_test_vet = f_test_vet.toarray()\n",
    "        \n",
    "           \n",
    "        try:\n",
    "            #Train the model\n",
    "            model.fit(f_train_vet, f_train[class_attribute], )\n",
    "            \n",
    "            #Predictions\n",
    "            predicted_classes =  model.predict(f_test_vet);\n",
    "\n",
    "            #Assign fold and predicted class to dataset to return\n",
    "            f_test['y_predicted'] = np.array(predicted_classes).transpose()\n",
    "            f_test['fold'] = k_i+1\n",
    "\n",
    "            #Store the class results to return\n",
    "            folds_return.append(f_test)\n",
    "            \n",
    "            if(verbose):\n",
    "                get_metrics(f_test, class_attribute, lbl_encoder, True)\n",
    "        except Exception as ex:\n",
    "            print('Except: ', ex)\n",
    "            break\n",
    "    \n",
    "    return folds_return\n",
    "\n",
    "# Show metrics\n",
    "def get_metrics(df, class_attribute, lbl_encoder, show=False):\n",
    "    \n",
    "    real = df[class_attribute]\n",
    "    predicted = df['y_predicted']\n",
    "    \n",
    "    f1 = metrics.f1_score(y_true = real, y_pred = predicted, average='macro').round(4)\n",
    "    accuracy = metrics.accuracy_score(y_true = real, y_pred = predicted ).round(4) \n",
    "    precision = metrics.precision_score(y_true = real, y_pred = predicted , average='macro').round(4)\n",
    "    recall = metrics.recall_score(y_true = real, y_pred = predicted , average='macro').round(4)\n",
    "    \n",
    "    if(show):\n",
    "        print('\\n','-'*20,'CONFUSION MATRIX','-'*20, '\\n')\n",
    "        matrix = confusion_matrix(y_true = real, y_pred = predicted )\n",
    "        cm = pd.DataFrame(matrix.T, columns=lbl_encoder.classes_, index = lbl_encoder.classes_)\n",
    "        print(cm) \n",
    "        #print(matriz.T)\n",
    "        print('\\n\\n')\n",
    "\n",
    "\n",
    "        print('-'*18,'CLASSIFICATION REPORT','-'*18)\n",
    "        print('\\n',metrics.classification_report(y_true = real, y_pred = predicted, \n",
    "                                            digits=2, target_names=lbl_encoder.classes_))\n",
    "\n",
    "        \n",
    "        print('-'*20,'GENERAL METRICS','-'*20)\n",
    "        print('\\nAccuracy', accuracy, '; Precision', precision, '; Recall', recall, '; F-Score', f1)\n",
    "        print('\\n')\n",
    "    \n",
    "    all_metrics = metrics.classification_report(y_true = real, y_pred = predicted , digits=4, \n",
    "                                         output_dict=True, target_names=lbl_encoder.classes_)\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, all_metrics, matrix.ravel()]   \n",
    "\n",
    "def normalizeRows(M):\n",
    "    sums = M.sum()\n",
    "    return M / sums\n",
    "\n",
    "def normalized_cm(df):\n",
    "    cm_df = df['Confusion_matrix'].sum()\n",
    "    cm_df = cm_df.reshape([5,5])\n",
    "    cm = pd.DataFrame(normalizeRows(cm_df), columns=lbl_multiclass.classes_, index = lbl_multiclass.classes_)\n",
    "    return cm.transpose()\n",
    "\n",
    "def mean_cm(df):\n",
    "    cm_df = df['Confusion_matrix'].sum()\n",
    "    cm_df = cm_df.reshape([5,5]) / 10\n",
    "    cm = pd.DataFrame(cm_df, columns=lbl_multiclass.classes_, index = lbl_multiclass.classes_)\n",
    "    return cm.transpose()\n",
    "\n",
    "def binary_normalized_cm(df):\n",
    "    cm_df = df['PositiveAndNegativeMetrics'].sum()\n",
    "    cm_df = cm_df.reshape([2,2])\n",
    "    cm = pd.DataFrame(normalizeRows(cm_df), columns=lbl_binary.classes_, index = lbl_binary.classes_)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f1e30",
   "metadata": {},
   "source": [
    "## Call load_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f7c6a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 444546\n",
      "Single words: 27062\n",
      "Short Description: 6\n",
      "Large Description: 261\n",
      "Mean Description: 170.9567655994391\n",
      "Standard Deviation: 44.68935911224313\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "loaded_data = load_data(\"tcm_expenses.xlsx\")\n",
    "freq = words_frequency(loaded_data, 'description').sort_values(by=['Frequency'], ascending=False, ignore_index=True)\n",
    "words_distribution(loaded_data, 'description')\n",
    "words_scatter(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a50018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total divergent instances = 3027\n",
      "Percent  17.685206824024306\n"
     ]
    }
   ],
   "source": [
    "total_divergent = len(loaded_data[loaded_data['class'] != loaded_data['expense_class_by_code']])\n",
    "print('Total divergent instances =', total_divergent)\n",
    "print('Percent ', (total_divergent / len(loaded_data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1c06dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_label, code_label = loaded_data['class'] , loaded_data['expense_class_by_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc1be5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>AJ</th>\n",
       "      <th>CRED</th>\n",
       "      <th>N</th>\n",
       "      <th>PA_PIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJ</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRED</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>276</td>\n",
       "      <td>13568</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA_PIP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AC  AJ  CRED      N  PA_PIP\n",
       "AC      75   0     1      0       0\n",
       "AJ       1  50     0      0       0\n",
       "CRED     0   0   396      0       0\n",
       "N       46  44   276  13568     105\n",
       "PA_PIP   0   0     0      0       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = metrics.confusion_matrix(y_true = manual_label, y_pred=code_label, labels=lbl_multiclass.classes_ )\n",
    "cm = pd.DataFrame(matrix.T, columns=lbl_multiclass.classes_, index = lbl_multiclass.classes_)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eaafa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>AJ</th>\n",
       "      <th>CRED</th>\n",
       "      <th>N</th>\n",
       "      <th>PA_PIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJ</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRED</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027194</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>0.93174</td>\n",
       "      <td>0.007211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA_PIP</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AC        AJ      CRED        N    PA_PIP\n",
       "AC      0.005150  0.000000  0.000069  0.00000  0.000000\n",
       "AJ      0.000069  0.003434  0.000000  0.00000  0.000000\n",
       "CRED    0.000000  0.000000  0.027194  0.00000  0.000000\n",
       "N       0.003159  0.003022  0.018953  0.93174  0.007211\n",
       "PA_PIP  0.000000  0.000000  0.000000  0.00000  0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'true', 'pred', 'all'\n",
    "matrix_normalized = metrics.confusion_matrix(y_true = manual_label, y_pred=code_label, \n",
    "                                             labels=lbl_multiclass.classes_ , normalize='all')\n",
    "cm_normalized = pd.DataFrame(matrix_normalized.T, columns=lbl_multiclass.classes_, index = lbl_multiclass.classes_)\n",
    "cm_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dd93b3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeba0603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal occurrence:  4\n",
      "8\n",
      "Minimal characters 4\n",
      "All dataset:  (16868, 11)\n",
      "After removing duplicates:  (16865, 11)\n",
      "After discarding no letters rows (16865, 11)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = data_cleaning(loaded_data, 'description', remove_stop_words=True, \n",
    "                        minimal_occurrence=4,\n",
    "                        minimal_characters=4).reset_index()\n",
    "frequency_after_data_cleaning = words_frequency(dataset, 'description').sort_values(by=['Frequency'], \n",
    "                                                                                    ascending=False, ignore_index=True)\n",
    "words_scatter(frequency_after_data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6339355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 167829\n",
      "Single words: 3417\n",
      "Short Description: 5\n",
      "Large Description: 194\n",
      "Mean Description: 88.61109793692198\n",
      "Standard Deviation: 29.27217546156147\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for tokens in dataset['description'].str.split() for word in tokens]\n",
    "dataset['sentence_lengths'] = [len(tokens) for tokens in dataset['description'].str.strip()]\n",
    "dataset['tokens'] = [tokens for tokens in dataset['description'].str.strip()]\n",
    "VOCAB = sorted(list(set(all_words)))\n",
    "\n",
    "print(\"Total words: %s\" % (len(all_words)))\n",
    "print(\"Single words: %s\" % (len(VOCAB)))\n",
    "print(\"Short Description: %s\" % min(dataset['sentence_lengths']))\n",
    "print(\"Large Description: %s\" % max(dataset['sentence_lengths']))\n",
    "print(\"Mean Description: %s\" % np.mean(dataset['sentence_lengths']))\n",
    "print(\"Standard Deviation: %s\" % np.std(dataset['sentence_lengths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd0f4b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>expense_description</th>\n",
       "      <th>amount</th>\n",
       "      <th>expense_code</th>\n",
       "      <th>expense_class_by_code</th>\n",
       "      <th>expense_class_by_expert</th>\n",
       "      <th>description</th>\n",
       "      <th>class</th>\n",
       "      <th>y_class</th>\n",
       "      <th>binary_class</th>\n",
       "      <th>y_binary_class</th>\n",
       "      <th>sentence_lengths</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1011</td>\n",
       "      <td>67853303</td>\n",
       "      <td>valor que se empenha para ocorrer a despesa co...</td>\n",
       "      <td>3333.25</td>\n",
       "      <td>31900400</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>ferias pagas</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>ferias pagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>1026</td>\n",
       "      <td>67884699</td>\n",
       "      <td>empenho da folha de pagamento de 13 salario19 ...</td>\n",
       "      <td>560.33</td>\n",
       "      <td>31900900</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>folha pagamento</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>folha pagamento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>1056</td>\n",
       "      <td>67804521</td>\n",
       "      <td>abono permanencia</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31901199</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>abono</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>abono</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1608</td>\n",
       "      <td>68175026</td>\n",
       "      <td>empenho da folha  saae 012020comissao 1673</td>\n",
       "      <td>2426.60</td>\n",
       "      <td>31901105</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>folha saae</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>folha saae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1650</td>\n",
       "      <td>67784284</td>\n",
       "      <td>valor que se empenha para atender despesa com ...</td>\n",
       "      <td>3254.03</td>\n",
       "      <td>31901103</td>\n",
       "      <td>PA</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>horas 2020.</td>\n",
       "      <td>PA_PIP</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>horas 2020.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13754</th>\n",
       "      <td>13945</td>\n",
       "      <td>68103699</td>\n",
       "      <td>aquisição de uma chave contador</td>\n",
       "      <td>725.41</td>\n",
       "      <td>33903026</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>aquisicao</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>aquisicao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13960</th>\n",
       "      <td>14160</td>\n",
       "      <td>68103641</td>\n",
       "      <td>despesa com atualização e cancelamento nirf.</td>\n",
       "      <td>680.00</td>\n",
       "      <td>33903999</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>atualizacao</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>atualizacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14574</th>\n",
       "      <td>14784</td>\n",
       "      <td>67804850</td>\n",
       "      <td>serviço medicos</td>\n",
       "      <td>52082.71</td>\n",
       "      <td>33903630</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>servico medicos</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>servico medicos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14872</th>\n",
       "      <td>15089</td>\n",
       "      <td>67804709</td>\n",
       "      <td>residentes precepores dezembro 2019</td>\n",
       "      <td>4774.29</td>\n",
       "      <td>31903499</td>\n",
       "      <td>OUTROS</td>\n",
       "      <td>N</td>\n",
       "      <td>dezembro 2019</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>dezembro 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15775</th>\n",
       "      <td>16000</td>\n",
       "      <td>67803479</td>\n",
       "      <td>manutenção das atividades/hospital raio x</td>\n",
       "      <td>368.00</td>\n",
       "      <td>33903036</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>manutencao raio</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>manutencao raio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        id                                expense_description   \n",
       "998     1011  67853303  valor que se empenha para ocorrer a despesa co...  \\\n",
       "1012    1026  67884699  empenho da folha de pagamento de 13 salario19 ...   \n",
       "1042    1056  67804521                                  abono permanencia   \n",
       "1578    1608  68175026         empenho da folha  saae 012020comissao 1673   \n",
       "1620    1650  67784284  valor que se empenha para atender despesa com ...   \n",
       "...      ...       ...                                                ...   \n",
       "13754  13945  68103699                    aquisição de uma chave contador   \n",
       "13960  14160  68103641       despesa com atualização e cancelamento nirf.   \n",
       "14574  14784  67804850                                    serviço medicos   \n",
       "14872  15089  67804709                residentes precepores dezembro 2019   \n",
       "15775  16000  67803479          manutenção das atividades/hospital raio x   \n",
       "\n",
       "         amount  expense_code expense_class_by_code expense_class_by_expert   \n",
       "998     3333.25      31900400                    PA                  PA_PIP  \\\n",
       "1012     560.33      31900900                    PA                  PA_PIP   \n",
       "1042       0.00      31901199                    PA                  PA_PIP   \n",
       "1578    2426.60      31901105                    PA                  PA_PIP   \n",
       "1620    3254.03      31901103                    PA                  PA_PIP   \n",
       "...         ...           ...                   ...                     ...   \n",
       "13754    725.41      33903026                     N                       N   \n",
       "13960    680.00      33903999                     N                       N   \n",
       "14574  52082.71      33903630                     N                       N   \n",
       "14872   4774.29      31903499                OUTROS                       N   \n",
       "15775    368.00      33903036                     N                       N   \n",
       "\n",
       "           description   class  y_class binary_class  y_binary_class   \n",
       "998       ferias pagas  PA_PIP        4            Y               1  \\\n",
       "1012   folha pagamento  PA_PIP        4            Y               1   \n",
       "1042             abono  PA_PIP        4            Y               1   \n",
       "1578        folha saae  PA_PIP        4            Y               1   \n",
       "1620       horas 2020.  PA_PIP        4            Y               1   \n",
       "...                ...     ...      ...          ...             ...   \n",
       "13754        aquisicao       N        3            N               0   \n",
       "13960      atualizacao       N        3            N               0   \n",
       "14574  servico medicos       N        3            N               0   \n",
       "14872    dezembro 2019       N        3            N               0   \n",
       "15775  manutencao raio       N        3            N               0   \n",
       "\n",
       "       sentence_lengths           tokens  \n",
       "998                  12     ferias pagas  \n",
       "1012                 15  folha pagamento  \n",
       "1042                  5            abono  \n",
       "1578                 10       folha saae  \n",
       "1620                 11      horas 2020.  \n",
       "...                 ...              ...  \n",
       "13754                 9        aquisicao  \n",
       "13960                11      atualizacao  \n",
       "14574                15  servico medicos  \n",
       "14872                13    dezembro 2019  \n",
       "15775                15  manutencao raio  \n",
       "\n",
       "[33 rows x 14 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.sentence_lengths <=15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80aae93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 167778\n",
      "Single words: 3409\n",
      "Short Description: 5\n",
      "Large Description: 194\n",
      "Mean Description: 88.60017788319004\n",
      "Standard Deviation: 29.268564340452734\n"
     ]
    }
   ],
   "source": [
    "words_distribution(dataset, 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc6579e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>intervencao</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>tarjeta</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>semusa</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>anulacao</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>cred</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prestacao</td>\n",
       "      <td>3263</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despesas</td>\n",
       "      <td>3493</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manutencao</td>\n",
       "      <td>3709</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>servicos</td>\n",
       "      <td>3975</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aquisicao</td>\n",
       "      <td>4281</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2605 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Frequency  Length\n",
       "2604  intervencao          4      11\n",
       "2599      tarjeta          4       7\n",
       "2600       semusa          4       6\n",
       "2603     anulacao          4       8\n",
       "2602         cred          4       4\n",
       "...           ...        ...     ...\n",
       "4       prestacao       3263       9\n",
       "3        despesas       3493       8\n",
       "2      manutencao       3709      10\n",
       "1        servicos       3975       8\n",
       "0       aquisicao       4281       9\n",
       "\n",
       "[2605 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_after_data_cleaning.sort_values(by=['Frequency'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f240a384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe: AC \n",
      "\n",
      "Total words: 1478\n",
      "Single words: 210\n",
      "Short Description: 43\n",
      "Large Description: 183\n",
      "Mean Description: 115.27642276422765\n",
      "Standard Deviation: 33.699364499812\n",
      "\n",
      "\n",
      "\n",
      "Classe: AJ \n",
      "\n",
      "Total words: 1028\n",
      "Single words: 203\n",
      "Short Description: 43\n",
      "Large Description: 179\n",
      "Mean Description: 107.7127659574468\n",
      "Standard Deviation: 31.699259116258414\n",
      "\n",
      "\n",
      "\n",
      "Classe: CRED \n",
      "\n",
      "Total words: 7811\n",
      "Single words: 587\n",
      "Short Description: 16\n",
      "Large Description: 187\n",
      "Mean Description: 105.99269005847954\n",
      "Standard Deviation: 26.381284441569125\n",
      "\n",
      "\n",
      "\n",
      "Classe: N \n",
      "\n",
      "Total words: 128296\n",
      "Single words: 2585\n",
      "Short Description: 4\n",
      "Large Description: 216\n",
      "Mean Description: 83.34598197934217\n",
      "Standard Deviation: 28.107051923317297\n",
      "\n",
      "\n",
      "\n",
      "Classe: PA_PIP \n",
      "\n",
      "Total words: 17832\n",
      "Single words: 988\n",
      "Short Description: 5\n",
      "Large Description: 180\n",
      "Mean Description: 66.95256087321579\n",
      "Standard Deviation: 22.69518048404712\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cls in lbl_multiclass.classes_:\n",
    "    print('Classe:',cls,'\\n')\n",
    "    words_distribution(dataset[dataset['class'] == cls], 'description')\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117f75f",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a46817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  0  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      99   1     0      1       0\n",
      "AJ       0  65     0      4       0\n",
      "CRED     0   0   554     32       3\n",
      "N       24  28   129  13509     208\n",
      "PA_PIP   0   0     1    105    2171\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.80      0.88       123\n",
      "          AJ       0.94      0.69      0.80        94\n",
      "        CRED       0.94      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.95      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.84      0.89     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9683 ; Precision 0.9577 ; Recall 0.8415 ; F-Score 0.8929\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  0  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      109   1     0      1       0\n",
      "AJ        0  69     0      4       0\n",
      "CRED      0   0   563     18       3\n",
      "N        14  24   120  13556     158\n",
      "PA_PIP    0   0     1     72    2221\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.89      0.93       123\n",
      "          AJ       0.95      0.73      0.83        94\n",
      "        CRED       0.96      0.82      0.89       684\n",
      "           N       0.98      0.99      0.99     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.97      0.87      0.92     16934\n",
      "weighted avg       0.98      0.98      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9754 ; Precision 0.9673 ; Recall 0.8738 ; F-Score 0.9162\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  0  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      32   0     0      0       0\n",
      "AJ       0   3     0      0       0\n",
      "CRED     0   1   525    113       1\n",
      "N       91  90   157  13201     151\n",
      "PA_PIP   0   0     2    337    2230\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.26      0.41       123\n",
      "          AJ       1.00      0.03      0.06        94\n",
      "        CRED       0.82      0.77      0.79       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.94      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.59      0.63     16934\n",
      "weighted avg       0.95      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9443 ; Precision 0.9305 ; Recall 0.5926 ; F-Score 0.6269\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  0  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14202   303\n",
      "Y    133  2296\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.98     14335\n",
      "           Y       0.95      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9743 ; Precision 0.9622 ; Recall 0.9371 ; F-Score 0.9491\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  0  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14251   201\n",
      "Y     84  2398\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.97      0.92      0.94      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9832 ; Precision 0.9761 ; Recall 0.9584 ; F-Score 0.967\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  0  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13973   237\n",
      "Y    362  2362\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.97      0.98     14335\n",
      "           Y       0.87      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.96     16934\n",
      "   macro avg       0.93      0.94      0.93     16934\n",
      "weighted avg       0.97      0.96      0.96     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9646 ; Precision 0.9252 ; Recall 0.9418 ; F-Score 0.9332\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  1  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      98   1     0      1       0\n",
      "AJ       0  65     0      3       0\n",
      "CRED     0   0   553     28       3\n",
      "N       25  28   130  13512     213\n",
      "PA_PIP   0   0     1    107    2166\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.80      0.88       123\n",
      "          AJ       0.96      0.69      0.80        94\n",
      "        CRED       0.95      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.95      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.84      0.89     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9681 ; Precision 0.9614 ; Recall 0.8392 ; F-Score 0.8929\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  1  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      108   1     0      1       0\n",
      "AJ        0  70     0      3       0\n",
      "CRED      0   0   558     20       3\n",
      "N        15  23   125  13556     159\n",
      "PA_PIP    0   0     1     71    2220\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.88      0.93       123\n",
      "          AJ       0.96      0.74      0.84        94\n",
      "        CRED       0.96      0.82      0.88       684\n",
      "           N       0.98      0.99      0.98     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.97      0.87      0.92     16934\n",
      "weighted avg       0.97      0.98      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9751 ; Precision 0.9693 ; Recall 0.8727 ; F-Score 0.9165\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  1  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      34   0     0      0       0\n",
      "AJ       0   3     0      0       0\n",
      "CRED     0   1   519    110       1\n",
      "N       89  90   163  13196     154\n",
      "PA_PIP   0   0     2    345    2227\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.28      0.43       123\n",
      "          AJ       1.00      0.03      0.06        94\n",
      "        CRED       0.82      0.76      0.79       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.93      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.59      0.63     16934\n",
      "weighted avg       0.94      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9436 ; Precision 0.9303 ; Recall 0.5937 ; F-Score 0.6297\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  1  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14205   309\n",
      "Y    130  2290\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.98     14335\n",
      "           Y       0.95      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9741 ; Precision 0.9625 ; Recall 0.936 ; F-Score 0.9487\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  1  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14257   198\n",
      "Y     78  2401\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.97      0.92      0.95      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9837 ; Precision 0.9774 ; Recall 0.9592 ; F-Score 0.968\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  1  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13971   235\n",
      "Y    364  2364\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.97      0.98     14335\n",
      "           Y       0.87      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.96     16934\n",
      "   macro avg       0.93      0.94      0.93     16934\n",
      "weighted avg       0.97      0.96      0.96     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9646 ; Precision 0.925 ; Recall 0.9421 ; F-Score 0.9333\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  2  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      100   1     0      0       0\n",
      "AJ        0  66     0      3       0\n",
      "CRED      0   0   555     31       3\n",
      "N        23  27   128  13512     211\n",
      "PA_PIP    0   0     1    105    2168\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.99      0.81      0.89       123\n",
      "          AJ       0.96      0.70      0.81        94\n",
      "        CRED       0.94      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.95      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.85      0.90     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9685 ; Precision 0.9629 ; Recall 0.8453 ; F-Score 0.8973\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  2  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      108   1     0      1       0\n",
      "AJ        0  71     0      3       0\n",
      "CRED      0   0   563     20       3\n",
      "N        15  22   120  13554     159\n",
      "PA_PIP    0   0     1     73    2220\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.88      0.93       123\n",
      "          AJ       0.96      0.76      0.85        94\n",
      "        CRED       0.96      0.82      0.89       684\n",
      "           N       0.98      0.99      0.98     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.97      0.88      0.92     16934\n",
      "weighted avg       0.98      0.98      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9753 ; Precision 0.9694 ; Recall 0.8763 ; F-Score 0.9187\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  2  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      35   0     0      0       0\n",
      "AJ       0   3     0      0       0\n",
      "CRED     0   1   519    115       1\n",
      "N       88  90   163  13203     151\n",
      "PA_PIP   0   0     2    333    2230\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.28      0.44       123\n",
      "          AJ       1.00      0.03      0.06        94\n",
      "        CRED       0.82      0.76      0.79       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.94      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.60      0.63     16934\n",
      "weighted avg       0.95      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9443 ; Precision 0.9299 ; Recall 0.5957 ; F-Score 0.6317\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  2  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14205   305\n",
      "Y    130  2294\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.98     14335\n",
      "           Y       0.95      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9743 ; Precision 0.9627 ; Recall 0.9368 ; F-Score 0.9492\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  2  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14250   198\n",
      "Y     85  2401\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.97      0.92      0.94      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9833 ; Precision 0.9761 ; Recall 0.9589 ; F-Score 0.9673\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  2  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13973   241\n",
      "Y    362  2358\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.97      0.98     14335\n",
      "           Y       0.87      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.96     16934\n",
      "   macro avg       0.92      0.94      0.93     16934\n",
      "weighted avg       0.97      0.96      0.96     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9644 ; Precision 0.925 ; Recall 0.941 ; F-Score 0.9328\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  3  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      99   1     0      1       0\n",
      "AJ       0  66     0      3       0\n",
      "CRED     0   0   554     30       3\n",
      "N       24  27   129  13516     211\n",
      "PA_PIP   0   0     1    101    2168\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.80      0.88       123\n",
      "          AJ       0.96      0.70      0.81        94\n",
      "        CRED       0.94      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.96      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.84      0.90     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9686 ; Precision 0.9615 ; Recall 0.8434 ; F-Score 0.8957\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  3  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      107   1     0      1       0\n",
      "AJ        0  68     0      4       0\n",
      "CRED      0   0   563     17       3\n",
      "N        16  25   120  13558     162\n",
      "PA_PIP    0   0     1     71    2217\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.87      0.92       123\n",
      "          AJ       0.94      0.72      0.82        94\n",
      "        CRED       0.97      0.82      0.89       684\n",
      "           N       0.98      0.99      0.98     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.97      0.87      0.91     16934\n",
      "weighted avg       0.97      0.98      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9751 ; Precision 0.9674 ; Recall 0.8681 ; F-Score 0.9129\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  3  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      33   0     0      0       0\n",
      "AJ       0   3     0      0       0\n",
      "CRED     0   1   524    111       1\n",
      "N       90  90   158  13197     159\n",
      "PA_PIP   0   0     2    343    2222\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.27      0.42       123\n",
      "          AJ       1.00      0.03      0.06        94\n",
      "        CRED       0.82      0.77      0.79       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.93      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.59      0.63     16934\n",
      "weighted avg       0.94      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9436 ; Precision 0.9304 ; Recall 0.5932 ; F-Score 0.6283\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  3  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14201   305\n",
      "Y    134  2294\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.98     14335\n",
      "           Y       0.94      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9741 ; Precision 0.9619 ; Recall 0.9366 ; F-Score 0.9487\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  3  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14247   206\n",
      "Y     88  2393\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.96      0.92      0.94      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9826 ; Precision 0.9751 ; Recall 0.9573 ; F-Score 0.966\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  3  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13975   240\n",
      "Y    360  2359\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.97      0.98     14335\n",
      "           Y       0.87      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.96     16934\n",
      "   macro avg       0.93      0.94      0.93     16934\n",
      "weighted avg       0.97      0.96      0.96     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9646 ; Precision 0.9254 ; Recall 0.9413 ; F-Score 0.9331\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  4  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      99   1     0      0       0\n",
      "AJ       0  67     0      4       0\n",
      "CRED     0   0   557     31       3\n",
      "N       24  26   126  13507     207\n",
      "PA_PIP   0   0     1    109    2172\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.99      0.80      0.89       123\n",
      "          AJ       0.94      0.71      0.81        94\n",
      "        CRED       0.94      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.95      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.85      0.90     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9686 ; Precision 0.9601 ; Recall 0.8467 ; F-Score 0.8972\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  4  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      109   1     0      1       0\n",
      "AJ        0  69     0      4       0\n",
      "CRED      0   0   566     18       3\n",
      "N        14  24   117  13553     156\n",
      "PA_PIP    0   0     1     75    2223\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.89      0.93       123\n",
      "          AJ       0.95      0.73      0.83        94\n",
      "        CRED       0.96      0.83      0.89       684\n",
      "           N       0.98      0.99      0.99     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.97      0.87      0.92     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9756 ; Precision 0.9672 ; Recall 0.8748 ; F-Score 0.9167\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  4  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      34   0     0      0       0\n",
      "AJ       0   2     0      0       0\n",
      "CRED     0   1   525    113       1\n",
      "N       89  91   157  13194     147\n",
      "PA_PIP   0   0     2    344    2234\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.28      0.43       123\n",
      "          AJ       1.00      0.02      0.04        94\n",
      "        CRED       0.82      0.77      0.79       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.94      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.59      0.63     16934\n",
      "weighted avg       0.95      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9442 ; Precision 0.9302 ; Recall 0.5939 ; F-Score 0.6268\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  4  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14206   303\n",
      "Y    129  2296\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.99     14335\n",
      "           Y       0.95      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9745 ; Precision 0.963 ; Recall 0.9372 ; F-Score 0.9495\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  4  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14254   197\n",
      "Y     81  2402\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.97      0.92      0.95      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9836 ; Precision 0.9769 ; Recall 0.9593 ; F-Score 0.9678\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  4  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13972   237\n",
      "Y    363  2362\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.97      0.98     14335\n",
      "           Y       0.87      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.96     16934\n",
      "   macro avg       0.93      0.94      0.93     16934\n",
      "weighted avg       0.97      0.96      0.96     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9646 ; Precision 0.9251 ; Recall 0.9417 ; F-Score 0.9331\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  5  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      99   1     0      0       0\n",
      "AJ       0  66     0      3       0\n",
      "CRED     0   0   555     28       3\n",
      "N       24  27   128  13516     214\n",
      "PA_PIP   0   0     1    104    2165\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.99      0.80      0.89       123\n",
      "          AJ       0.96      0.70      0.81        94\n",
      "        CRED       0.95      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.95      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.84      0.90     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9685 ; Precision 0.9638 ; Recall 0.8435 ; F-Score 0.8967\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  5  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      109   1     0      1       0\n",
      "AJ        0  69     0      3       0\n",
      "CRED      0   0   564     23       3\n",
      "N        14  24   119  13547     159\n",
      "PA_PIP    0   0     1     77    2220\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.89      0.93       123\n",
      "          AJ       0.96      0.73      0.83        94\n",
      "        CRED       0.96      0.82      0.89       684\n",
      "           N       0.98      0.99      0.98     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.97      0.87      0.92     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9749 ; Precision 0.9679 ; Recall 0.8738 ; F-Score 0.9164\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  5  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      34   0     0      0       0\n",
      "AJ       0   3     0      0       0\n",
      "CRED     0   1   518    109       1\n",
      "N       89  90   165  13205     150\n",
      "PA_PIP   0   0     1    337    2231\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.28      0.43       123\n",
      "          AJ       1.00      0.03      0.06        94\n",
      "        CRED       0.82      0.76      0.79       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.94      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.59      0.63     16934\n",
      "weighted avg       0.95      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9443 ; Precision 0.9312 ; Recall 0.5939 ; F-Score 0.6302\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  5  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14202   299\n",
      "Y    133  2300\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.99     14335\n",
      "           Y       0.95      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9745 ; Precision 0.9624 ; Recall 0.9378 ; F-Score 0.9496\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  5  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14253   196\n",
      "Y     82  2403\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.97      0.92      0.95      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9836 ; Precision 0.9767 ; Recall 0.9594 ; F-Score 0.9678\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  5  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13981   236\n",
      "Y    354  2363\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.98      0.98     14335\n",
      "           Y       0.87      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.93      0.94      0.93     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9652 ; Precision 0.9266 ; Recall 0.9423 ; F-Score 0.9342\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  6  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      100   1     0      0       0\n",
      "AJ        0  66     0      3       0\n",
      "CRED      0   0   556     31       3\n",
      "N        23  27   127  13510     210\n",
      "PA_PIP    0   0     1    107    2169\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.99      0.81      0.89       123\n",
      "          AJ       0.96      0.70      0.81        94\n",
      "        CRED       0.94      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.95      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.85      0.90     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9685 ; Precision 0.9627 ; Recall 0.8457 ; F-Score 0.8975\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  6  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      109   1     0      1       0\n",
      "AJ        0  71     0      4       0\n",
      "CRED      0   0   562     17       3\n",
      "N        14  22   121  13557     158\n",
      "PA_PIP    0   0     1     72    2221\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.89      0.93       123\n",
      "          AJ       0.95      0.76      0.84        94\n",
      "        CRED       0.97      0.82      0.89       684\n",
      "           N       0.98      0.99      0.99     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.97      0.88      0.92     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9756 ; Precision 0.968 ; Recall 0.8777 ; F-Score 0.919\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  6  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      34   0     0      0       0\n",
      "AJ       0   3     0      0       0\n",
      "CRED     0   1   520    116       1\n",
      "N       89  90   162  13199     153\n",
      "PA_PIP   0   0     2    336    2228\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.28      0.43       123\n",
      "          AJ       1.00      0.03      0.06        94\n",
      "        CRED       0.82      0.76      0.79       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.94      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.59      0.63     16934\n",
      "weighted avg       0.94      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9439 ; Precision 0.9294 ; Recall 0.5942 ; F-Score 0.6295\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  6  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14206   304\n",
      "Y    129  2295\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.98     14335\n",
      "           Y       0.95      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9744 ; Precision 0.9629 ; Recall 0.937 ; F-Score 0.9494\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  6  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14249   202\n",
      "Y     86  2397\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.97      0.92      0.94      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.983 ; Precision 0.9757 ; Recall 0.9581 ; F-Score 0.9667\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  6  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13971   237\n",
      "Y    364  2362\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.97      0.98     14335\n",
      "           Y       0.87      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.96     16934\n",
      "   macro avg       0.92      0.94      0.93     16934\n",
      "weighted avg       0.97      0.96      0.96     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9645 ; Precision 0.9249 ; Recall 0.9417 ; F-Score 0.933\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  7  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      99   1     0      0       0\n",
      "AJ       0  67     0      4       0\n",
      "CRED     0   0   551     30       3\n",
      "N       24  26   132  13510     207\n",
      "PA_PIP   0   0     1    107    2172\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.99      0.80      0.89       123\n",
      "          AJ       0.94      0.71      0.81        94\n",
      "        CRED       0.94      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.95      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.84      0.90     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9684 ; Precision 0.9604 ; Recall 0.8449 ; F-Score 0.8963\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  7  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      108   1     0      1       0\n",
      "AJ        0  69     0      4       0\n",
      "CRED      0   0   564     21       3\n",
      "N        15  24   119  13555     161\n",
      "PA_PIP    0   0     1     70    2218\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.88      0.93       123\n",
      "          AJ       0.95      0.73      0.83        94\n",
      "        CRED       0.96      0.82      0.89       684\n",
      "           N       0.98      0.99      0.98     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.97      0.87      0.91     16934\n",
      "weighted avg       0.98      0.98      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9752 ; Precision 0.9664 ; Recall 0.8722 ; F-Score 0.915\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  7  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      35   0     0      0       0\n",
      "AJ       0   3     0      0       0\n",
      "CRED     0   1   524    112       1\n",
      "N       88  90   159  13198     150\n",
      "PA_PIP   0   0     1    341    2231\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.28      0.44       123\n",
      "          AJ       1.00      0.03      0.06        94\n",
      "        CRED       0.82      0.77      0.79       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.94      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.60      0.63     16934\n",
      "weighted avg       0.95      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9443 ; Precision 0.9306 ; Recall 0.5972 ; F-Score 0.6327\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  7  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14206   306\n",
      "Y    129  2293\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.98     14335\n",
      "           Y       0.95      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9743 ; Precision 0.9628 ; Recall 0.9366 ; F-Score 0.9491\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  7  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14258   198\n",
      "Y     77  2401\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.97      0.92      0.95      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9838 ; Precision 0.9776 ; Recall 0.9592 ; F-Score 0.9681\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  7  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13976   234\n",
      "Y    359  2365\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.97      0.98     14335\n",
      "           Y       0.87      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.96     16934\n",
      "   macro avg       0.93      0.94      0.93     16934\n",
      "weighted avg       0.97      0.96      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.965 ; Precision 0.9259 ; Recall 0.9425 ; F-Score 0.9339\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  8  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      100   1     0      1       0\n",
      "AJ        0  66     0      4       0\n",
      "CRED      0   0   555     31       3\n",
      "N        23  27   128  13507     212\n",
      "PA_PIP    0   0     1    108    2167\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.81      0.89       123\n",
      "          AJ       0.94      0.70      0.80        94\n",
      "        CRED       0.94      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.95      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.85      0.90     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9682 ; Precision 0.9579 ; Recall 0.8451 ; F-Score 0.8954\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  8  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      108   1     0      1       0\n",
      "AJ        0  70     0      4       0\n",
      "CRED      0   0   561     17       3\n",
      "N        15  23   122  13554     162\n",
      "PA_PIP    0   0     1     75    2217\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.88      0.93       123\n",
      "          AJ       0.95      0.74      0.83        94\n",
      "        CRED       0.97      0.82      0.89       684\n",
      "           N       0.98      0.99      0.98     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.97      0.87      0.92     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.975 ; Precision 0.9674 ; Recall 0.8733 ; F-Score 0.9161\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  8  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      35   0     0      0       0\n",
      "AJ       0   3     0      0       0\n",
      "CRED     0   1   520    115       1\n",
      "N       88  90   162  13198     150\n",
      "PA_PIP   0   0     2    338    2231\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.28      0.44       123\n",
      "          AJ       1.00      0.03      0.06        94\n",
      "        CRED       0.82      0.76      0.79       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.94      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.60      0.63     16934\n",
      "weighted avg       0.95      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9441 ; Precision 0.9297 ; Recall 0.596 ; F-Score 0.6317\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  8  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14201   301\n",
      "Y    134  2298\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.98     14335\n",
      "           Y       0.94      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9743 ; Precision 0.9621 ; Recall 0.9374 ; F-Score 0.9492\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  8  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14259   196\n",
      "Y     76  2403\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.97      0.92      0.95      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9839 ; Precision 0.9779 ; Recall 0.9596 ; F-Score 0.9685\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  8  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13963   236\n",
      "Y    372  2363\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.97      0.98     14335\n",
      "           Y       0.86      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.96     16934\n",
      "   macro avg       0.92      0.94      0.93     16934\n",
      "weighted avg       0.97      0.96      0.96     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9641 ; Precision 0.9237 ; Recall 0.9416 ; F-Score 0.9324\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  9  Approach:  multiclass  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      99   1     0      0       0\n",
      "AJ       0  64     0      4       0\n",
      "CRED     0   0   553     26       3\n",
      "N       24  29   130  13517     219\n",
      "PA_PIP   0   0     1    104    2160\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.99      0.80      0.89       123\n",
      "          AJ       0.94      0.68      0.79        94\n",
      "        CRED       0.95      0.81      0.87       684\n",
      "           N       0.97      0.99      0.98     13651\n",
      "      PA_PIP       0.95      0.91      0.93      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.84      0.89     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9681 ; Precision 0.9612 ; Recall 0.8382 ; F-Score 0.8924\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  9  Approach:  multiclass  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "         AC  AJ  CRED      N  PA_PIP\n",
      "AC      109   1     0      1       0\n",
      "AJ        0  71     0      4       0\n",
      "CRED      0   0   561     19       3\n",
      "N        14  22   122  13555     168\n",
      "PA_PIP    0   0     1     72    2211\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.98      0.89      0.93       123\n",
      "          AJ       0.95      0.76      0.84        94\n",
      "        CRED       0.96      0.82      0.89       684\n",
      "           N       0.98      0.99      0.98     13651\n",
      "      PA_PIP       0.97      0.93      0.95      2382\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.97      0.88      0.92     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9748 ; Precision 0.9671 ; Recall 0.8766 ; F-Score 0.918\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  9  Approach:  multiclass  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "        AC  AJ  CRED      N  PA_PIP\n",
      "AC      36   0     0      0       0\n",
      "AJ       0   3     0      0       0\n",
      "CRED     0   1   516    113       1\n",
      "N       87  90   166  13200     148\n",
      "PA_PIP   0   0     2    338    2233\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          AC       1.00      0.29      0.45       123\n",
      "          AJ       1.00      0.03      0.06        94\n",
      "        CRED       0.82      0.75      0.78       684\n",
      "           N       0.96      0.97      0.97     13651\n",
      "      PA_PIP       0.87      0.94      0.90      2382\n",
      "\n",
      "    accuracy                           0.94     16934\n",
      "   macro avg       0.93      0.60      0.63     16934\n",
      "weighted avg       0.95      0.94      0.94     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9441 ; Precision 0.9299 ; Recall 0.5967 ; F-Score 0.6333\n",
      "\n",
      "\n",
      "Splitint the dataset into k = 10\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  9  Approach:  binary  Model:  LogisticRegression()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14203   303\n",
      "Y    132  2296\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.99      0.98     14335\n",
      "           Y       0.95      0.88      0.91      2599\n",
      "\n",
      "    accuracy                           0.97     16934\n",
      "   macro avg       0.96      0.94      0.95     16934\n",
      "weighted avg       0.97      0.97      0.97     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9743 ; Precision 0.9624 ; Recall 0.9371 ; F-Score 0.9492\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  9  Approach:  binary  Model:  SVC()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  14254   203\n",
      "Y     81  2396\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     14335\n",
      "           Y       0.97      0.92      0.94      2599\n",
      "\n",
      "    accuracy                           0.98     16934\n",
      "   macro avg       0.98      0.96      0.97     16934\n",
      "weighted avg       0.98      0.98      0.98     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9832 ; Precision 0.9766 ; Recall 0.9581 ; F-Score 0.9671\n",
      "\n",
      "\n",
      "######################################################################\n",
      "EXPERIMENT -> Seed  9  Approach:  binary  Model:  MultinomialNB()\n",
      "######################################################################\n",
      "\n",
      " -------------------- CONFUSION MATRIX -------------------- \n",
      "\n",
      "       N     Y\n",
      "N  13971   240\n",
      "Y    364  2359\n",
      "\n",
      "\n",
      "\n",
      "------------------ CLASSIFICATION REPORT ------------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.98      0.97      0.98     14335\n",
      "           Y       0.87      0.91      0.89      2599\n",
      "\n",
      "    accuracy                           0.96     16934\n",
      "   macro avg       0.92      0.94      0.93     16934\n",
      "weighted avg       0.97      0.96      0.96     16934\n",
      "\n",
      "-------------------- GENERAL METRICS --------------------\n",
      "\n",
      "Accuracy 0.9643 ; Precision 0.9247 ; Recall 0.9411 ; F-Score 0.9327\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definitions\n",
    "models = [LogisticRegression(), SVC(), MultinomialNB()]\n",
    "#models = [SVC()]\n",
    "classes = {'multiclass': ['y_class', lbl_multiclass], 'binary': ['y_binary_class', lbl_binary]}\n",
    "\n",
    "metrics_all_models = list()\n",
    "\n",
    "seeds = range(0,10)\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    for approach, lbl_config in classes.items():\n",
    "        \n",
    "        class_attribute = lbl_config[0]\n",
    "        encoder = lbl_config[1]\n",
    "        \n",
    "        #split the data\n",
    "        folds = split_data(dataset, label=class_attribute, seed=seed)\n",
    "\n",
    "        for model in models:\n",
    "            print('#'*70)\n",
    "            print('EXPERIMENT -> Seed ', seed, ' Approach: ', approach, ' Model: ', model)\n",
    "            print('#'*70)\n",
    "            folds_return = prediction(model, folds, class_attribute, lbl_encoder=encoder)\n",
    "            metrics_model = [str(seed), str(model), approach]\n",
    "            metrics_model.extend(get_metrics(pd.concat(folds_return), class_attribute, encoder, show=True))\n",
    "            metrics_all_models.append(metrics_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c789f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Model</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>All Metrics</th>\n",
       "      <th>PositiveAndNegativeMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>{'AC': {'precision': 0.9801980198019802, 'reca...</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 65, 0, 28, 0, 0, 0, 554, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>{'AC': {'precision': 0.9819819819819819, 'reca...</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.9305</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6269</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.26016260...</td>\n",
       "      <td>[32, 0, 0, 91, 0, 0, 3, 1, 90, 0, 0, 0, 525, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>{'N': {'precision': 0.979110651499483, 'recall...</td>\n",
       "      <td>[14202, 133, 303, 2296]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>{'N': {'precision': 0.9860918903957929, 'recal...</td>\n",
       "      <td>[14251, 84, 201, 2398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9252</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>{'N': {'precision': 0.9833216045038705, 'recal...</td>\n",
       "      <td>[13973, 362, 237, 2362]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>{'AC': {'precision': 0.98, 'recall': 0.7967479...</td>\n",
       "      <td>[98, 0, 0, 25, 0, 1, 65, 0, 28, 0, 0, 0, 553, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>{'AC': {'precision': 0.9818181818181818, 'reca...</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9303</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.27642276...</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>{'N': {'precision': 0.9787102108309219, 'recal...</td>\n",
       "      <td>[14205, 130, 309, 2290]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>{'N': {'precision': 0.9863023175371843, 'recal...</td>\n",
       "      <td>[14257, 78, 198, 2401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>{'N': {'precision': 0.9834576939321413, 'recal...</td>\n",
       "      <td>[13971, 364, 235, 2364]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>{'AC': {'precision': 0.9900990099009901, 'reca...</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>{'AC': {'precision': 0.9818181818181818, 'reca...</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.28455284...</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>{'N': {'precision': 0.9789800137835976, 'recal...</td>\n",
       "      <td>[14205, 130, 305, 2294]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>{'N': {'precision': 0.9862956810631229, 'recal...</td>\n",
       "      <td>[14250, 85, 198, 2401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>{'N': {'precision': 0.9830448853243281, 'recal...</td>\n",
       "      <td>[13973, 362, 241, 2358]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.8434</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>{'AC': {'precision': 0.9801980198019802, 'reca...</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 554, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>{'AC': {'precision': 0.981651376146789, 'recal...</td>\n",
       "      <td>[107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.26829268...</td>\n",
       "      <td>[33, 0, 0, 90, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>{'N': {'precision': 0.9789742175651455, 'recal...</td>\n",
       "      <td>[14201, 134, 305, 2294]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>{'N': {'precision': 0.9857469037570055, 'recal...</td>\n",
       "      <td>[14247, 88, 206, 2393]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>{'N': {'precision': 0.9831164263102357, 'recal...</td>\n",
       "      <td>[13975, 360, 240, 2359]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>{'AC': {'precision': 0.99, 'recall': 0.8048780...</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 557, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>{'AC': {'precision': 0.9819819819819819, 'reca...</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>0.6268</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.27642276...</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 2, 1, 91, 0, 0, 0, 525, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>{'N': {'precision': 0.9791164105038253, 'recal...</td>\n",
       "      <td>[14206, 129, 303, 2296]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>{'N': {'precision': 0.9863677254169262, 'recal...</td>\n",
       "      <td>[14254, 81, 197, 2402]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>{'N': {'precision': 0.9833204307129284, 'recal...</td>\n",
       "      <td>[13972, 363, 237, 2362]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>{'AC': {'precision': 0.99, 'recall': 0.8048780...</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 555, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>{'AC': {'precision': 0.9819819819819819, 'reca...</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>0.6302</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.27642276...</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 518, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.9378</td>\n",
       "      <td>0.9496</td>\n",
       "      <td>{'N': {'precision': 0.9793807323632853, 'recal...</td>\n",
       "      <td>[14202, 133, 299, 2300]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>{'N': {'precision': 0.9864350474081252, 'recal...</td>\n",
       "      <td>[14253, 82, 196, 2403]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>{'N': {'precision': 0.9834001547443202, 'recal...</td>\n",
       "      <td>[13981, 354, 236, 2363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>{'AC': {'precision': 0.9900990099009901, 'reca...</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 556,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>{'AC': {'precision': 0.9819819819819819, 'reca...</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9439</td>\n",
       "      <td>0.9294</td>\n",
       "      <td>0.5942</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.27642276...</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>{'N': {'precision': 0.9790489317711922, 'recal...</td>\n",
       "      <td>[14206, 129, 304, 2295]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>{'N': {'precision': 0.9860217286000968, 'recal...</td>\n",
       "      <td>[14249, 86, 202, 2397]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>{'N': {'precision': 0.9833192567567568, 'recal...</td>\n",
       "      <td>[13971, 364, 237, 2362]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.8449</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>{'AC': {'precision': 0.99, 'recall': 0.8048780...</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 551, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.8722</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>{'AC': {'precision': 0.9818181818181818, 'reca...</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>7</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>0.5972</td>\n",
       "      <td>0.6327</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.28455284...</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>{'N': {'precision': 0.9789140022050716, 'recal...</td>\n",
       "      <td>[14206, 129, 306, 2293]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>{'N': {'precision': 0.9863032650802435, 'recal...</td>\n",
       "      <td>[14258, 77, 198, 2401]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.9339</td>\n",
       "      <td>{'N': {'precision': 0.9835327234342013, 'recal...</td>\n",
       "      <td>[13976, 359, 234, 2365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.8954</td>\n",
       "      <td>{'AC': {'precision': 0.9803921568627451, 'reca...</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>{'AC': {'precision': 0.9818181818181818, 'reca...</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>8</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.9297</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.28455284...</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>{'N': {'precision': 0.9792442421734933, 'recal...</td>\n",
       "      <td>[14201, 134, 301, 2298]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>{'N': {'precision': 0.9864406779661017, 'recal...</td>\n",
       "      <td>[14259, 76, 196, 2403]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>8</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.9416</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>{'N': {'precision': 0.9833791112050144, 'recal...</td>\n",
       "      <td>[13963, 372, 236, 2363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>0.8382</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>{'AC': {'precision': 0.99, 'recall': 0.8048780...</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 64, 0, 29, 0, 0, 0, 553, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>{'AC': {'precision': 0.9819819819819819, 'reca...</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>9</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.5967</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>{'AC': {'precision': 1.0, 'recall': 0.29268292...</td>\n",
       "      <td>[36, 0, 0, 87, 0, 0, 3, 1, 90, 0, 0, 0, 516, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>{'N': {'precision': 0.9791120915483248, 'recal...</td>\n",
       "      <td>[14203, 132, 303, 2296]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>9</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>{'N': {'precision': 0.9859583592723248, 'recal...</td>\n",
       "      <td>[14254, 81, 203, 2396]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>9</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.9411</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>{'N': {'precision': 0.9831116740553093, 'recal...</td>\n",
       "      <td>[13971, 364, 240, 2359]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seed                 Model    Approach  Accuracy  Precision  Recall  \\\n",
       "0     0  LogisticRegression()  multiclass    0.9683     0.9577  0.8415   \n",
       "1     0                 SVC()  multiclass    0.9754     0.9673  0.8738   \n",
       "2     0       MultinomialNB()  multiclass    0.9443     0.9305  0.5926   \n",
       "3     0  LogisticRegression()      binary    0.9743     0.9622  0.9371   \n",
       "4     0                 SVC()      binary    0.9832     0.9761  0.9584   \n",
       "5     0       MultinomialNB()      binary    0.9646     0.9252  0.9418   \n",
       "6     1  LogisticRegression()  multiclass    0.9681     0.9614  0.8392   \n",
       "7     1                 SVC()  multiclass    0.9751     0.9693  0.8727   \n",
       "8     1       MultinomialNB()  multiclass    0.9436     0.9303  0.5937   \n",
       "9     1  LogisticRegression()      binary    0.9741     0.9625  0.9360   \n",
       "10    1                 SVC()      binary    0.9837     0.9774  0.9592   \n",
       "11    1       MultinomialNB()      binary    0.9646     0.9250  0.9421   \n",
       "12    2  LogisticRegression()  multiclass    0.9685     0.9629  0.8453   \n",
       "13    2                 SVC()  multiclass    0.9753     0.9694  0.8763   \n",
       "14    2       MultinomialNB()  multiclass    0.9443     0.9299  0.5957   \n",
       "15    2  LogisticRegression()      binary    0.9743     0.9627  0.9368   \n",
       "16    2                 SVC()      binary    0.9833     0.9761  0.9589   \n",
       "17    2       MultinomialNB()      binary    0.9644     0.9250  0.9410   \n",
       "18    3  LogisticRegression()  multiclass    0.9686     0.9615  0.8434   \n",
       "19    3                 SVC()  multiclass    0.9751     0.9674  0.8681   \n",
       "20    3       MultinomialNB()  multiclass    0.9436     0.9304  0.5932   \n",
       "21    3  LogisticRegression()      binary    0.9741     0.9619  0.9366   \n",
       "22    3                 SVC()      binary    0.9826     0.9751  0.9573   \n",
       "23    3       MultinomialNB()      binary    0.9646     0.9254  0.9413   \n",
       "24    4  LogisticRegression()  multiclass    0.9686     0.9601  0.8467   \n",
       "25    4                 SVC()  multiclass    0.9756     0.9672  0.8748   \n",
       "26    4       MultinomialNB()  multiclass    0.9442     0.9302  0.5939   \n",
       "27    4  LogisticRegression()      binary    0.9745     0.9630  0.9372   \n",
       "28    4                 SVC()      binary    0.9836     0.9769  0.9593   \n",
       "29    4       MultinomialNB()      binary    0.9646     0.9251  0.9417   \n",
       "30    5  LogisticRegression()  multiclass    0.9685     0.9638  0.8435   \n",
       "31    5                 SVC()  multiclass    0.9749     0.9679  0.8738   \n",
       "32    5       MultinomialNB()  multiclass    0.9443     0.9312  0.5939   \n",
       "33    5  LogisticRegression()      binary    0.9745     0.9624  0.9378   \n",
       "34    5                 SVC()      binary    0.9836     0.9767  0.9594   \n",
       "35    5       MultinomialNB()      binary    0.9652     0.9266  0.9423   \n",
       "36    6  LogisticRegression()  multiclass    0.9685     0.9627  0.8457   \n",
       "37    6                 SVC()  multiclass    0.9756     0.9680  0.8777   \n",
       "38    6       MultinomialNB()  multiclass    0.9439     0.9294  0.5942   \n",
       "39    6  LogisticRegression()      binary    0.9744     0.9629  0.9370   \n",
       "40    6                 SVC()      binary    0.9830     0.9757  0.9581   \n",
       "41    6       MultinomialNB()      binary    0.9645     0.9249  0.9417   \n",
       "42    7  LogisticRegression()  multiclass    0.9684     0.9604  0.8449   \n",
       "43    7                 SVC()  multiclass    0.9752     0.9664  0.8722   \n",
       "44    7       MultinomialNB()  multiclass    0.9443     0.9306  0.5972   \n",
       "45    7  LogisticRegression()      binary    0.9743     0.9628  0.9366   \n",
       "46    7                 SVC()      binary    0.9838     0.9776  0.9592   \n",
       "47    7       MultinomialNB()      binary    0.9650     0.9259  0.9425   \n",
       "48    8  LogisticRegression()  multiclass    0.9682     0.9579  0.8451   \n",
       "49    8                 SVC()  multiclass    0.9750     0.9674  0.8733   \n",
       "50    8       MultinomialNB()  multiclass    0.9441     0.9297  0.5960   \n",
       "51    8  LogisticRegression()      binary    0.9743     0.9621  0.9374   \n",
       "52    8                 SVC()      binary    0.9839     0.9779  0.9596   \n",
       "53    8       MultinomialNB()      binary    0.9641     0.9237  0.9416   \n",
       "54    9  LogisticRegression()  multiclass    0.9681     0.9612  0.8382   \n",
       "55    9                 SVC()  multiclass    0.9748     0.9671  0.8766   \n",
       "56    9       MultinomialNB()  multiclass    0.9441     0.9299  0.5967   \n",
       "57    9  LogisticRegression()      binary    0.9743     0.9624  0.9371   \n",
       "58    9                 SVC()      binary    0.9832     0.9766  0.9581   \n",
       "59    9       MultinomialNB()      binary    0.9643     0.9247  0.9411   \n",
       "\n",
       "        F1                                        All Metrics  \\\n",
       "0   0.8929  {'AC': {'precision': 0.9801980198019802, 'reca...   \n",
       "1   0.9162  {'AC': {'precision': 0.9819819819819819, 'reca...   \n",
       "2   0.6269  {'AC': {'precision': 1.0, 'recall': 0.26016260...   \n",
       "3   0.9491  {'N': {'precision': 0.979110651499483, 'recall...   \n",
       "4   0.9670  {'N': {'precision': 0.9860918903957929, 'recal...   \n",
       "5   0.9332  {'N': {'precision': 0.9833216045038705, 'recal...   \n",
       "6   0.8929  {'AC': {'precision': 0.98, 'recall': 0.7967479...   \n",
       "7   0.9165  {'AC': {'precision': 0.9818181818181818, 'reca...   \n",
       "8   0.6297  {'AC': {'precision': 1.0, 'recall': 0.27642276...   \n",
       "9   0.9487  {'N': {'precision': 0.9787102108309219, 'recal...   \n",
       "10  0.9680  {'N': {'precision': 0.9863023175371843, 'recal...   \n",
       "11  0.9333  {'N': {'precision': 0.9834576939321413, 'recal...   \n",
       "12  0.8973  {'AC': {'precision': 0.9900990099009901, 'reca...   \n",
       "13  0.9187  {'AC': {'precision': 0.9818181818181818, 'reca...   \n",
       "14  0.6317  {'AC': {'precision': 1.0, 'recall': 0.28455284...   \n",
       "15  0.9492  {'N': {'precision': 0.9789800137835976, 'recal...   \n",
       "16  0.9673  {'N': {'precision': 0.9862956810631229, 'recal...   \n",
       "17  0.9328  {'N': {'precision': 0.9830448853243281, 'recal...   \n",
       "18  0.8957  {'AC': {'precision': 0.9801980198019802, 'reca...   \n",
       "19  0.9129  {'AC': {'precision': 0.981651376146789, 'recal...   \n",
       "20  0.6283  {'AC': {'precision': 1.0, 'recall': 0.26829268...   \n",
       "21  0.9487  {'N': {'precision': 0.9789742175651455, 'recal...   \n",
       "22  0.9660  {'N': {'precision': 0.9857469037570055, 'recal...   \n",
       "23  0.9331  {'N': {'precision': 0.9831164263102357, 'recal...   \n",
       "24  0.8972  {'AC': {'precision': 0.99, 'recall': 0.8048780...   \n",
       "25  0.9167  {'AC': {'precision': 0.9819819819819819, 'reca...   \n",
       "26  0.6268  {'AC': {'precision': 1.0, 'recall': 0.27642276...   \n",
       "27  0.9495  {'N': {'precision': 0.9791164105038253, 'recal...   \n",
       "28  0.9678  {'N': {'precision': 0.9863677254169262, 'recal...   \n",
       "29  0.9331  {'N': {'precision': 0.9833204307129284, 'recal...   \n",
       "30  0.8967  {'AC': {'precision': 0.99, 'recall': 0.8048780...   \n",
       "31  0.9164  {'AC': {'precision': 0.9819819819819819, 'reca...   \n",
       "32  0.6302  {'AC': {'precision': 1.0, 'recall': 0.27642276...   \n",
       "33  0.9496  {'N': {'precision': 0.9793807323632853, 'recal...   \n",
       "34  0.9678  {'N': {'precision': 0.9864350474081252, 'recal...   \n",
       "35  0.9342  {'N': {'precision': 0.9834001547443202, 'recal...   \n",
       "36  0.8975  {'AC': {'precision': 0.9900990099009901, 'reca...   \n",
       "37  0.9190  {'AC': {'precision': 0.9819819819819819, 'reca...   \n",
       "38  0.6295  {'AC': {'precision': 1.0, 'recall': 0.27642276...   \n",
       "39  0.9494  {'N': {'precision': 0.9790489317711922, 'recal...   \n",
       "40  0.9667  {'N': {'precision': 0.9860217286000968, 'recal...   \n",
       "41  0.9330  {'N': {'precision': 0.9833192567567568, 'recal...   \n",
       "42  0.8963  {'AC': {'precision': 0.99, 'recall': 0.8048780...   \n",
       "43  0.9150  {'AC': {'precision': 0.9818181818181818, 'reca...   \n",
       "44  0.6327  {'AC': {'precision': 1.0, 'recall': 0.28455284...   \n",
       "45  0.9491  {'N': {'precision': 0.9789140022050716, 'recal...   \n",
       "46  0.9681  {'N': {'precision': 0.9863032650802435, 'recal...   \n",
       "47  0.9339  {'N': {'precision': 0.9835327234342013, 'recal...   \n",
       "48  0.8954  {'AC': {'precision': 0.9803921568627451, 'reca...   \n",
       "49  0.9161  {'AC': {'precision': 0.9818181818181818, 'reca...   \n",
       "50  0.6317  {'AC': {'precision': 1.0, 'recall': 0.28455284...   \n",
       "51  0.9492  {'N': {'precision': 0.9792442421734933, 'recal...   \n",
       "52  0.9685  {'N': {'precision': 0.9864406779661017, 'recal...   \n",
       "53  0.9324  {'N': {'precision': 0.9833791112050144, 'recal...   \n",
       "54  0.8924  {'AC': {'precision': 0.99, 'recall': 0.8048780...   \n",
       "55  0.9180  {'AC': {'precision': 0.9819819819819819, 'reca...   \n",
       "56  0.6333  {'AC': {'precision': 1.0, 'recall': 0.29268292...   \n",
       "57  0.9492  {'N': {'precision': 0.9791120915483248, 'recal...   \n",
       "58  0.9671  {'N': {'precision': 0.9859583592723248, 'recal...   \n",
       "59  0.9327  {'N': {'precision': 0.9831116740553093, 'recal...   \n",
       "\n",
       "                           PositiveAndNegativeMetrics  \n",
       "0   [99, 0, 0, 24, 0, 1, 65, 0, 28, 0, 0, 0, 554, ...  \n",
       "1   [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...  \n",
       "2   [32, 0, 0, 91, 0, 0, 3, 1, 90, 0, 0, 0, 525, 1...  \n",
       "3                             [14202, 133, 303, 2296]  \n",
       "4                              [14251, 84, 201, 2398]  \n",
       "5                             [13973, 362, 237, 2362]  \n",
       "6   [98, 0, 0, 25, 0, 1, 65, 0, 28, 0, 0, 0, 553, ...  \n",
       "7   [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...  \n",
       "8   [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...  \n",
       "9                             [14205, 130, 309, 2290]  \n",
       "10                             [14257, 78, 198, 2401]  \n",
       "11                            [13971, 364, 235, 2364]  \n",
       "12  [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...  \n",
       "13  [108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...  \n",
       "14  [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...  \n",
       "15                            [14205, 130, 305, 2294]  \n",
       "16                             [14250, 85, 198, 2401]  \n",
       "17                            [13973, 362, 241, 2358]  \n",
       "18  [99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 554, ...  \n",
       "19  [107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...  \n",
       "20  [33, 0, 0, 90, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...  \n",
       "21                            [14201, 134, 305, 2294]  \n",
       "22                             [14247, 88, 206, 2393]  \n",
       "23                            [13975, 360, 240, 2359]  \n",
       "24  [99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 557, ...  \n",
       "25  [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...  \n",
       "26  [34, 0, 0, 89, 0, 0, 2, 1, 91, 0, 0, 0, 525, 1...  \n",
       "27                            [14206, 129, 303, 2296]  \n",
       "28                             [14254, 81, 197, 2402]  \n",
       "29                            [13972, 363, 237, 2362]  \n",
       "30  [99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 555, ...  \n",
       "31  [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...  \n",
       "32  [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 518, 1...  \n",
       "33                            [14202, 133, 299, 2300]  \n",
       "34                             [14253, 82, 196, 2403]  \n",
       "35                            [13981, 354, 236, 2363]  \n",
       "36  [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 556,...  \n",
       "37  [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...  \n",
       "38  [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...  \n",
       "39                            [14206, 129, 304, 2295]  \n",
       "40                             [14249, 86, 202, 2397]  \n",
       "41                            [13971, 364, 237, 2362]  \n",
       "42  [99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 551, ...  \n",
       "43  [108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...  \n",
       "44  [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...  \n",
       "45                            [14206, 129, 306, 2293]  \n",
       "46                             [14258, 77, 198, 2401]  \n",
       "47                            [13976, 359, 234, 2365]  \n",
       "48  [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...  \n",
       "49  [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...  \n",
       "50  [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...  \n",
       "51                            [14201, 134, 301, 2298]  \n",
       "52                             [14259, 76, 196, 2403]  \n",
       "53                            [13963, 372, 236, 2363]  \n",
       "54  [99, 0, 0, 24, 0, 1, 64, 0, 29, 0, 0, 0, 553, ...  \n",
       "55  [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...  \n",
       "56  [36, 0, 0, 87, 0, 0, 3, 1, 90, 0, 0, 0, 516, 1...  \n",
       "57                            [14203, 132, 303, 2296]  \n",
       "58                             [14254, 81, 203, 2396]  \n",
       "59                            [13971, 364, 240, 2359]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df_results = pd.DataFrame(metrics_all_models, columns=['Seed', 'Model', 'Approach', 'Accuracy', 'Precision', 'Recall', 'F1', 'All Metrics', 'PositiveAndNegativeMetrics'])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9114f6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>PositiveAndNegativeMetrics</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>Y_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>[14202, 133, 303, 2296]</td>\n",
       "      <td>0.984882</td>\n",
       "      <td>0.913286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>[14251, 84, 201, 2398]</td>\n",
       "      <td>0.990100</td>\n",
       "      <td>0.943909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9252</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>[13973, 362, 237, 2362]</td>\n",
       "      <td>0.979016</td>\n",
       "      <td>0.887469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>[14205, 130, 309, 2290]</td>\n",
       "      <td>0.984783</td>\n",
       "      <td>0.912532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>[14257, 78, 198, 2401]</td>\n",
       "      <td>0.990413</td>\n",
       "      <td>0.945648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>[13971, 364, 235, 2364]</td>\n",
       "      <td>0.979013</td>\n",
       "      <td>0.887554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>[14205, 130, 305, 2294]</td>\n",
       "      <td>0.984919</td>\n",
       "      <td>0.913398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>[14250, 85, 198, 2401]</td>\n",
       "      <td>0.990168</td>\n",
       "      <td>0.944346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>[13973, 362, 241, 2358]</td>\n",
       "      <td>0.978878</td>\n",
       "      <td>0.886633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>[14201, 134, 305, 2294]</td>\n",
       "      <td>0.984779</td>\n",
       "      <td>0.912672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>[14247, 88, 206, 2393]</td>\n",
       "      <td>0.989787</td>\n",
       "      <td>0.942126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>[13975, 360, 240, 2359]</td>\n",
       "      <td>0.978984</td>\n",
       "      <td>0.887176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>[14206, 129, 303, 2296]</td>\n",
       "      <td>0.985023</td>\n",
       "      <td>0.914013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>[14254, 81, 197, 2402]</td>\n",
       "      <td>0.990343</td>\n",
       "      <td>0.945297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>[13972, 363, 237, 2362]</td>\n",
       "      <td>0.978980</td>\n",
       "      <td>0.887303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.9378</td>\n",
       "      <td>0.9496</td>\n",
       "      <td>[14202, 133, 299, 2300]</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.914149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>[14253, 82, 196, 2403]</td>\n",
       "      <td>0.990342</td>\n",
       "      <td>0.945319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>[13981, 354, 236, 2363]</td>\n",
       "      <td>0.979336</td>\n",
       "      <td>0.889014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>[14206, 129, 304, 2295]</td>\n",
       "      <td>0.984989</td>\n",
       "      <td>0.913797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>[14249, 86, 202, 2397]</td>\n",
       "      <td>0.989995</td>\n",
       "      <td>0.943329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>[13971, 364, 237, 2362]</td>\n",
       "      <td>0.978944</td>\n",
       "      <td>0.887136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>[14206, 129, 306, 2293]</td>\n",
       "      <td>0.984920</td>\n",
       "      <td>0.913364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>[14258, 77, 198, 2401]</td>\n",
       "      <td>0.990448</td>\n",
       "      <td>0.945834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.9339</td>\n",
       "      <td>[13976, 359, 234, 2365]</td>\n",
       "      <td>0.979226</td>\n",
       "      <td>0.888597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>[14201, 134, 301, 2298]</td>\n",
       "      <td>0.984915</td>\n",
       "      <td>0.913536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>[14259, 76, 196, 2403]</td>\n",
       "      <td>0.990552</td>\n",
       "      <td>0.946436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.9416</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>[13963, 372, 236, 2363]</td>\n",
       "      <td>0.978692</td>\n",
       "      <td>0.886014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>[14203, 132, 303, 2296]</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>0.913467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>[14254, 81, 203, 2396]</td>\n",
       "      <td>0.990136</td>\n",
       "      <td>0.944050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.9411</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>[13971, 364, 240, 2359]</td>\n",
       "      <td>0.978841</td>\n",
       "      <td>0.886509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Approach  Accuracy  Precision  Recall      F1  \\\n",
       "Seed                                                                       \n",
       "0     LogisticRegression()   binary    0.9743     0.9622  0.9371  0.9491   \n",
       "0                    SVC()   binary    0.9832     0.9761  0.9584  0.9670   \n",
       "0          MultinomialNB()   binary    0.9646     0.9252  0.9418  0.9332   \n",
       "1     LogisticRegression()   binary    0.9741     0.9625  0.9360  0.9487   \n",
       "1                    SVC()   binary    0.9837     0.9774  0.9592  0.9680   \n",
       "1          MultinomialNB()   binary    0.9646     0.9250  0.9421  0.9333   \n",
       "2     LogisticRegression()   binary    0.9743     0.9627  0.9368  0.9492   \n",
       "2                    SVC()   binary    0.9833     0.9761  0.9589  0.9673   \n",
       "2          MultinomialNB()   binary    0.9644     0.9250  0.9410  0.9328   \n",
       "3     LogisticRegression()   binary    0.9741     0.9619  0.9366  0.9487   \n",
       "3                    SVC()   binary    0.9826     0.9751  0.9573  0.9660   \n",
       "3          MultinomialNB()   binary    0.9646     0.9254  0.9413  0.9331   \n",
       "4     LogisticRegression()   binary    0.9745     0.9630  0.9372  0.9495   \n",
       "4                    SVC()   binary    0.9836     0.9769  0.9593  0.9678   \n",
       "4          MultinomialNB()   binary    0.9646     0.9251  0.9417  0.9331   \n",
       "5     LogisticRegression()   binary    0.9745     0.9624  0.9378  0.9496   \n",
       "5                    SVC()   binary    0.9836     0.9767  0.9594  0.9678   \n",
       "5          MultinomialNB()   binary    0.9652     0.9266  0.9423  0.9342   \n",
       "6     LogisticRegression()   binary    0.9744     0.9629  0.9370  0.9494   \n",
       "6                    SVC()   binary    0.9830     0.9757  0.9581  0.9667   \n",
       "6          MultinomialNB()   binary    0.9645     0.9249  0.9417  0.9330   \n",
       "7     LogisticRegression()   binary    0.9743     0.9628  0.9366  0.9491   \n",
       "7                    SVC()   binary    0.9838     0.9776  0.9592  0.9681   \n",
       "7          MultinomialNB()   binary    0.9650     0.9259  0.9425  0.9339   \n",
       "8     LogisticRegression()   binary    0.9743     0.9621  0.9374  0.9492   \n",
       "8                    SVC()   binary    0.9839     0.9779  0.9596  0.9685   \n",
       "8          MultinomialNB()   binary    0.9641     0.9237  0.9416  0.9324   \n",
       "9     LogisticRegression()   binary    0.9743     0.9624  0.9371  0.9492   \n",
       "9                    SVC()   binary    0.9832     0.9766  0.9581  0.9671   \n",
       "9          MultinomialNB()   binary    0.9643     0.9247  0.9411  0.9327   \n",
       "\n",
       "     PositiveAndNegativeMetrics      N_F1      Y_F1  \n",
       "Seed                                                 \n",
       "0       [14202, 133, 303, 2296]  0.984882  0.913286  \n",
       "0        [14251, 84, 201, 2398]  0.990100  0.943909  \n",
       "0       [13973, 362, 237, 2362]  0.979016  0.887469  \n",
       "1       [14205, 130, 309, 2290]  0.984783  0.912532  \n",
       "1        [14257, 78, 198, 2401]  0.990413  0.945648  \n",
       "1       [13971, 364, 235, 2364]  0.979013  0.887554  \n",
       "2       [14205, 130, 305, 2294]  0.984919  0.913398  \n",
       "2        [14250, 85, 198, 2401]  0.990168  0.944346  \n",
       "2       [13973, 362, 241, 2358]  0.978878  0.886633  \n",
       "3       [14201, 134, 305, 2294]  0.984779  0.912672  \n",
       "3        [14247, 88, 206, 2393]  0.989787  0.942126  \n",
       "3       [13975, 360, 240, 2359]  0.978984  0.887176  \n",
       "4       [14206, 129, 303, 2296]  0.985023  0.914013  \n",
       "4        [14254, 81, 197, 2402]  0.990343  0.945297  \n",
       "4       [13972, 363, 237, 2362]  0.978980  0.887303  \n",
       "5       [14202, 133, 299, 2300]  0.985019  0.914149  \n",
       "5        [14253, 82, 196, 2403]  0.990342  0.945319  \n",
       "5       [13981, 354, 236, 2363]  0.979336  0.889014  \n",
       "6       [14206, 129, 304, 2295]  0.984989  0.913797  \n",
       "6        [14249, 86, 202, 2397]  0.989995  0.943329  \n",
       "6       [13971, 364, 237, 2362]  0.978944  0.887136  \n",
       "7       [14206, 129, 306, 2293]  0.984920  0.913364  \n",
       "7        [14258, 77, 198, 2401]  0.990448  0.945834  \n",
       "7       [13976, 359, 234, 2365]  0.979226  0.888597  \n",
       "8       [14201, 134, 301, 2298]  0.984915  0.913536  \n",
       "8        [14259, 76, 196, 2403]  0.990552  0.946436  \n",
       "8       [13963, 372, 236, 2363]  0.978692  0.886014  \n",
       "9       [14203, 132, 303, 2296]  0.984917  0.913467  \n",
       "9        [14254, 81, 203, 2396]  0.990136  0.944050  \n",
       "9       [13971, 364, 240, 2359]  0.978841  0.886509  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_binary = df_results[df_results.Approach == 'binary'].set_index('Seed')\n",
    "\n",
    "for lbl in lbl_binary.classes_:\n",
    "    #df_results_binary[lbl+'_P'] = df_results_binary['All Metrics'].apply(lambda x:x[lbl]['precision'])\n",
    "    #df_results_binary[lbl+'_R'] = df_results_binary['All Metrics'].apply(lambda x:x[lbl]['recall'])\n",
    "    df_results_binary[lbl+'_F1'] = df_results_binary['All Metrics'].apply(lambda x:x[lbl]['f1-score'])\n",
    "\n",
    "df_results_binary.drop(columns=['All Metrics'], inplace=True)\n",
    "df_results_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ada903e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>PositiveAndNegativeMetrics</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>Y_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>[14202, 133, 303, 2296]</td>\n",
       "      <td>0.984882</td>\n",
       "      <td>0.913286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>[14251, 84, 201, 2398]</td>\n",
       "      <td>0.990100</td>\n",
       "      <td>0.943909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9252</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>[13973, 362, 237, 2362]</td>\n",
       "      <td>0.979016</td>\n",
       "      <td>0.887469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>[14205, 130, 309, 2290]</td>\n",
       "      <td>0.984783</td>\n",
       "      <td>0.912532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>[14257, 78, 198, 2401]</td>\n",
       "      <td>0.990413</td>\n",
       "      <td>0.945648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>[13971, 364, 235, 2364]</td>\n",
       "      <td>0.979013</td>\n",
       "      <td>0.887554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>[14205, 130, 305, 2294]</td>\n",
       "      <td>0.984919</td>\n",
       "      <td>0.913398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>[14250, 85, 198, 2401]</td>\n",
       "      <td>0.990168</td>\n",
       "      <td>0.944346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>[13973, 362, 241, 2358]</td>\n",
       "      <td>0.978878</td>\n",
       "      <td>0.886633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>[14201, 134, 305, 2294]</td>\n",
       "      <td>0.984779</td>\n",
       "      <td>0.912672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>[14247, 88, 206, 2393]</td>\n",
       "      <td>0.989787</td>\n",
       "      <td>0.942126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>[13975, 360, 240, 2359]</td>\n",
       "      <td>0.978984</td>\n",
       "      <td>0.887176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>[14206, 129, 303, 2296]</td>\n",
       "      <td>0.985023</td>\n",
       "      <td>0.914013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>[14254, 81, 197, 2402]</td>\n",
       "      <td>0.990343</td>\n",
       "      <td>0.945297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>[13972, 363, 237, 2362]</td>\n",
       "      <td>0.978980</td>\n",
       "      <td>0.887303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.9378</td>\n",
       "      <td>0.9496</td>\n",
       "      <td>[14202, 133, 299, 2300]</td>\n",
       "      <td>0.985019</td>\n",
       "      <td>0.914149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>[14253, 82, 196, 2403]</td>\n",
       "      <td>0.990342</td>\n",
       "      <td>0.945319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>[13981, 354, 236, 2363]</td>\n",
       "      <td>0.979336</td>\n",
       "      <td>0.889014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>[14206, 129, 304, 2295]</td>\n",
       "      <td>0.984989</td>\n",
       "      <td>0.913797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>[14249, 86, 202, 2397]</td>\n",
       "      <td>0.989995</td>\n",
       "      <td>0.943329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>[13971, 364, 237, 2362]</td>\n",
       "      <td>0.978944</td>\n",
       "      <td>0.887136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>[14206, 129, 306, 2293]</td>\n",
       "      <td>0.984920</td>\n",
       "      <td>0.913364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>[14258, 77, 198, 2401]</td>\n",
       "      <td>0.990448</td>\n",
       "      <td>0.945834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.9339</td>\n",
       "      <td>[13976, 359, 234, 2365]</td>\n",
       "      <td>0.979226</td>\n",
       "      <td>0.888597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>[14201, 134, 301, 2298]</td>\n",
       "      <td>0.984915</td>\n",
       "      <td>0.913536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>[14259, 76, 196, 2403]</td>\n",
       "      <td>0.990552</td>\n",
       "      <td>0.946436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.9416</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>[13963, 372, 236, 2363]</td>\n",
       "      <td>0.978692</td>\n",
       "      <td>0.886014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>[14203, 132, 303, 2296]</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>0.913467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>[14254, 81, 203, 2396]</td>\n",
       "      <td>0.990136</td>\n",
       "      <td>0.944050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.9411</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>[13971, 364, 240, 2359]</td>\n",
       "      <td>0.978841</td>\n",
       "      <td>0.886509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Approach  Accuracy  Precision  Recall      F1  \\\n",
       "Seed                                                                       \n",
       "0     LogisticRegression()   binary    0.9743     0.9622  0.9371  0.9491   \n",
       "0                    SVC()   binary    0.9832     0.9761  0.9584  0.9670   \n",
       "0          MultinomialNB()   binary    0.9646     0.9252  0.9418  0.9332   \n",
       "1     LogisticRegression()   binary    0.9741     0.9625  0.9360  0.9487   \n",
       "1                    SVC()   binary    0.9837     0.9774  0.9592  0.9680   \n",
       "1          MultinomialNB()   binary    0.9646     0.9250  0.9421  0.9333   \n",
       "2     LogisticRegression()   binary    0.9743     0.9627  0.9368  0.9492   \n",
       "2                    SVC()   binary    0.9833     0.9761  0.9589  0.9673   \n",
       "2          MultinomialNB()   binary    0.9644     0.9250  0.9410  0.9328   \n",
       "3     LogisticRegression()   binary    0.9741     0.9619  0.9366  0.9487   \n",
       "3                    SVC()   binary    0.9826     0.9751  0.9573  0.9660   \n",
       "3          MultinomialNB()   binary    0.9646     0.9254  0.9413  0.9331   \n",
       "4     LogisticRegression()   binary    0.9745     0.9630  0.9372  0.9495   \n",
       "4                    SVC()   binary    0.9836     0.9769  0.9593  0.9678   \n",
       "4          MultinomialNB()   binary    0.9646     0.9251  0.9417  0.9331   \n",
       "5     LogisticRegression()   binary    0.9745     0.9624  0.9378  0.9496   \n",
       "5                    SVC()   binary    0.9836     0.9767  0.9594  0.9678   \n",
       "5          MultinomialNB()   binary    0.9652     0.9266  0.9423  0.9342   \n",
       "6     LogisticRegression()   binary    0.9744     0.9629  0.9370  0.9494   \n",
       "6                    SVC()   binary    0.9830     0.9757  0.9581  0.9667   \n",
       "6          MultinomialNB()   binary    0.9645     0.9249  0.9417  0.9330   \n",
       "7     LogisticRegression()   binary    0.9743     0.9628  0.9366  0.9491   \n",
       "7                    SVC()   binary    0.9838     0.9776  0.9592  0.9681   \n",
       "7          MultinomialNB()   binary    0.9650     0.9259  0.9425  0.9339   \n",
       "8     LogisticRegression()   binary    0.9743     0.9621  0.9374  0.9492   \n",
       "8                    SVC()   binary    0.9839     0.9779  0.9596  0.9685   \n",
       "8          MultinomialNB()   binary    0.9641     0.9237  0.9416  0.9324   \n",
       "9     LogisticRegression()   binary    0.9743     0.9624  0.9371  0.9492   \n",
       "9                    SVC()   binary    0.9832     0.9766  0.9581  0.9671   \n",
       "9          MultinomialNB()   binary    0.9643     0.9247  0.9411  0.9327   \n",
       "\n",
       "     PositiveAndNegativeMetrics      N_F1      Y_F1  \n",
       "Seed                                                 \n",
       "0       [14202, 133, 303, 2296]  0.984882  0.913286  \n",
       "0        [14251, 84, 201, 2398]  0.990100  0.943909  \n",
       "0       [13973, 362, 237, 2362]  0.979016  0.887469  \n",
       "1       [14205, 130, 309, 2290]  0.984783  0.912532  \n",
       "1        [14257, 78, 198, 2401]  0.990413  0.945648  \n",
       "1       [13971, 364, 235, 2364]  0.979013  0.887554  \n",
       "2       [14205, 130, 305, 2294]  0.984919  0.913398  \n",
       "2        [14250, 85, 198, 2401]  0.990168  0.944346  \n",
       "2       [13973, 362, 241, 2358]  0.978878  0.886633  \n",
       "3       [14201, 134, 305, 2294]  0.984779  0.912672  \n",
       "3        [14247, 88, 206, 2393]  0.989787  0.942126  \n",
       "3       [13975, 360, 240, 2359]  0.978984  0.887176  \n",
       "4       [14206, 129, 303, 2296]  0.985023  0.914013  \n",
       "4        [14254, 81, 197, 2402]  0.990343  0.945297  \n",
       "4       [13972, 363, 237, 2362]  0.978980  0.887303  \n",
       "5       [14202, 133, 299, 2300]  0.985019  0.914149  \n",
       "5        [14253, 82, 196, 2403]  0.990342  0.945319  \n",
       "5       [13981, 354, 236, 2363]  0.979336  0.889014  \n",
       "6       [14206, 129, 304, 2295]  0.984989  0.913797  \n",
       "6        [14249, 86, 202, 2397]  0.989995  0.943329  \n",
       "6       [13971, 364, 237, 2362]  0.978944  0.887136  \n",
       "7       [14206, 129, 306, 2293]  0.984920  0.913364  \n",
       "7        [14258, 77, 198, 2401]  0.990448  0.945834  \n",
       "7       [13976, 359, 234, 2365]  0.979226  0.888597  \n",
       "8       [14201, 134, 301, 2298]  0.984915  0.913536  \n",
       "8        [14259, 76, 196, 2403]  0.990552  0.946436  \n",
       "8       [13963, 372, 236, 2363]  0.978692  0.886014  \n",
       "9       [14203, 132, 303, 2296]  0.984917  0.913467  \n",
       "9        [14254, 81, 203, 2396]  0.990136  0.944050  \n",
       "9       [13971, 364, 240, 2359]  0.978841  0.886509  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59537191",
   "metadata": {},
   "source": [
    "## Resultados do modelo SVM Binário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "def80208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>Y_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  Precision  Recall    F1  N_F1  Y_F1\n",
       "mean      0.98       0.98    0.96  0.97  0.99  0.94\n",
       "std       0.00       0.00    0.00  0.00  0.00  0.00"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary_svc = df_results_binary[df_results_binary.Model == 'SVC()']\n",
    "df_binary_svc.describe()[1:3].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f37ce88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>Y_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.9134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  Precision  Recall      F1    N_F1    Y_F1\n",
       "mean    0.9743     0.9625  0.9370  0.9492  0.9849  0.9134\n",
       "std     0.0001     0.0004  0.0005  0.0003  0.0001  0.0005"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_binary[df_results_binary.Model == 'LogisticRegression()'].describe()[1:3].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5aacf41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>Y_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.9252</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.8873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  Precision  Recall      F1    N_F1    Y_F1\n",
       "mean    0.9646     0.9252  0.9417  0.9332  0.9790  0.8873\n",
       "std     0.0003     0.0008  0.0005  0.0005  0.0002  0.0009"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_binary[df_results_binary.Model == 'MultinomialNB()'].describe()[1:3].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39cea495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Repetição 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Repetição 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Repetição 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Repetição 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Repetição 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Repetição 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Repetição 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Repetição 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Repetição 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Repetição 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              X\n",
       "0   Repetição 1\n",
       "1   Repetição 2\n",
       "2   Repetição 3\n",
       "3   Repetição 4\n",
       "4   Repetição 5\n",
       "5   Repetição 6\n",
       "6   Repetição 7\n",
       "7   Repetição 8\n",
       "8   Repetição 9\n",
       "9  Repetição 10"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_x = pd.DataFrame(range(0,10), columns=['X'])\n",
    "label_x.X = label_x.X.apply(lambda x: ('Repetição ' + str(x+1)))\n",
    "label_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124d877",
   "metadata": {},
   "source": [
    "f = plt.figure(figsize=(10, 7)) \n",
    "plt.title('Experimento Binário - E1')\n",
    "plt.ylabel('F1')\n",
    "plt.plot(label_x.X, df_results_binary[df_results_binary.Model == 'LogisticRegression()'].F1, marker=\".\",c='green', label='LogisticRegression')\n",
    "plt.plot(label_x.X, df_results_binary[df_results_binary.Model == 'SVC()'].F1, marker=\".\",c='red', label='SVC')\n",
    "plt.plot(label_x.X, df_results_binary[df_results_binary.Model == 'MultinomialNB()'].F1, marker=\".\",c='blue', label='MultinomialNB')\n",
    "plt.grid(True)\n",
    "plt.legend(bbox_to_anchor = (0.99,0.8))\n",
    "f.autofmt_xdate()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d18637fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seed\n",
       "0    0.9670\n",
       "1    0.9680\n",
       "2    0.9673\n",
       "3    0.9660\n",
       "4    0.9678\n",
       "5    0.9678\n",
       "6    0.9667\n",
       "7    0.9681\n",
       "8    0.9685\n",
       "9    0.9671\n",
       "Name: F1, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary_svc.F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fce7ff",
   "metadata": {},
   "source": [
    "df_results_binary.groupby(['Model']).mean().round(3).sort_values(by=['F1'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea4e8ec",
   "metadata": {},
   "source": [
    "df_results_binary.sort_values(by=['F1'], ascending=False).groupby(['Model']).std().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54278696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>PositiveAndNegativeMetrics</th>\n",
       "      <th>AC_F1</th>\n",
       "      <th>AJ_F1</th>\n",
       "      <th>CRED_F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>PA_PIP_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 65, 0, 28, 0, 0, 0, 554, ...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[32, 0, 0, 91, 0, 0, 3, 1, 90, 0, 0, 0, 525, 1...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>[98, 0, 0, 25, 0, 1, 65, 0, 28, 0, 0, 0, 553, ...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 554, ...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.91</td>\n",
       "      <td>[107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[33, 0, 0, 90, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 557, ...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 2, 1, 91, 0, 0, 0, 525, 1...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 555, ...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 518, 1...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 556,...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 551, ...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 64, 0, 29, 0, 0, 0, 553, ...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>[36, 0, 0, 87, 0, 0, 3, 1, 90, 0, 0, 0, 516, 1...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model    Approach  Accuracy  Precision  Recall    F1  \\\n",
       "Seed                                                                        \n",
       "0     LogisticRegression()  multiclass      0.97       0.96    0.84  0.89   \n",
       "0                    SVC()  multiclass      0.98       0.97    0.87  0.92   \n",
       "0          MultinomialNB()  multiclass      0.94       0.93    0.59  0.63   \n",
       "1     LogisticRegression()  multiclass      0.97       0.96    0.84  0.89   \n",
       "1                    SVC()  multiclass      0.98       0.97    0.87  0.92   \n",
       "1          MultinomialNB()  multiclass      0.94       0.93    0.59  0.63   \n",
       "2     LogisticRegression()  multiclass      0.97       0.96    0.85  0.90   \n",
       "2                    SVC()  multiclass      0.98       0.97    0.88  0.92   \n",
       "2          MultinomialNB()  multiclass      0.94       0.93    0.60  0.63   \n",
       "3     LogisticRegression()  multiclass      0.97       0.96    0.84  0.90   \n",
       "3                    SVC()  multiclass      0.98       0.97    0.87  0.91   \n",
       "3          MultinomialNB()  multiclass      0.94       0.93    0.59  0.63   \n",
       "4     LogisticRegression()  multiclass      0.97       0.96    0.85  0.90   \n",
       "4                    SVC()  multiclass      0.98       0.97    0.87  0.92   \n",
       "4          MultinomialNB()  multiclass      0.94       0.93    0.59  0.63   \n",
       "5     LogisticRegression()  multiclass      0.97       0.96    0.84  0.90   \n",
       "5                    SVC()  multiclass      0.97       0.97    0.87  0.92   \n",
       "5          MultinomialNB()  multiclass      0.94       0.93    0.59  0.63   \n",
       "6     LogisticRegression()  multiclass      0.97       0.96    0.85  0.90   \n",
       "6                    SVC()  multiclass      0.98       0.97    0.88  0.92   \n",
       "6          MultinomialNB()  multiclass      0.94       0.93    0.59  0.63   \n",
       "7     LogisticRegression()  multiclass      0.97       0.96    0.84  0.90   \n",
       "7                    SVC()  multiclass      0.98       0.97    0.87  0.92   \n",
       "7          MultinomialNB()  multiclass      0.94       0.93    0.60  0.63   \n",
       "8     LogisticRegression()  multiclass      0.97       0.96    0.85  0.90   \n",
       "8                    SVC()  multiclass      0.98       0.97    0.87  0.92   \n",
       "8          MultinomialNB()  multiclass      0.94       0.93    0.60  0.63   \n",
       "9     LogisticRegression()  multiclass      0.97       0.96    0.84  0.89   \n",
       "9                    SVC()  multiclass      0.97       0.97    0.88  0.92   \n",
       "9          MultinomialNB()  multiclass      0.94       0.93    0.60  0.63   \n",
       "\n",
       "                             PositiveAndNegativeMetrics  AC_F1  AJ_F1  \\\n",
       "Seed                                                                    \n",
       "0     [99, 0, 0, 24, 0, 1, 65, 0, 28, 0, 0, 0, 554, ...   0.88   0.80   \n",
       "0     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...   0.93   0.83   \n",
       "0     [32, 0, 0, 91, 0, 0, 3, 1, 90, 0, 0, 0, 525, 1...   0.41   0.06   \n",
       "1     [98, 0, 0, 25, 0, 1, 65, 0, 28, 0, 0, 0, 553, ...   0.88   0.80   \n",
       "1     [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...   0.93   0.84   \n",
       "1     [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...   0.43   0.06   \n",
       "2     [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...   0.89   0.81   \n",
       "2     [108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...   0.93   0.85   \n",
       "2     [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...   0.44   0.06   \n",
       "3     [99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 554, ...   0.88   0.81   \n",
       "3     [107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...   0.92   0.82   \n",
       "3     [33, 0, 0, 90, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...   0.42   0.06   \n",
       "4     [99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 557, ...   0.89   0.81   \n",
       "4     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...   0.93   0.83   \n",
       "4     [34, 0, 0, 89, 0, 0, 2, 1, 91, 0, 0, 0, 525, 1...   0.43   0.04   \n",
       "5     [99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 555, ...   0.89   0.81   \n",
       "5     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...   0.93   0.83   \n",
       "5     [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 518, 1...   0.43   0.06   \n",
       "6     [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 556,...   0.89   0.81   \n",
       "6     [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...   0.93   0.84   \n",
       "6     [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...   0.43   0.06   \n",
       "7     [99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 551, ...   0.89   0.81   \n",
       "7     [108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...   0.93   0.83   \n",
       "7     [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...   0.44   0.06   \n",
       "8     [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...   0.89   0.80   \n",
       "8     [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...   0.93   0.83   \n",
       "8     [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...   0.44   0.06   \n",
       "9     [99, 0, 0, 24, 0, 1, 64, 0, 29, 0, 0, 0, 553, ...   0.89   0.79   \n",
       "9     [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...   0.93   0.84   \n",
       "9     [36, 0, 0, 87, 0, 0, 3, 1, 90, 0, 0, 0, 516, 1...   0.45   0.06   \n",
       "\n",
       "      CRED_F1  N_F1  PA_PIP_F1  \n",
       "Seed                            \n",
       "0        0.87  0.98       0.93  \n",
       "0        0.89  0.99       0.95  \n",
       "0        0.79  0.97       0.90  \n",
       "1        0.87  0.98       0.93  \n",
       "1        0.88  0.98       0.95  \n",
       "1        0.79  0.97       0.90  \n",
       "2        0.87  0.98       0.93  \n",
       "2        0.89  0.98       0.95  \n",
       "2        0.79  0.97       0.90  \n",
       "3        0.87  0.98       0.93  \n",
       "3        0.89  0.98       0.95  \n",
       "3        0.79  0.97       0.90  \n",
       "4        0.87  0.98       0.93  \n",
       "4        0.89  0.99       0.95  \n",
       "4        0.79  0.97       0.90  \n",
       "5        0.87  0.98       0.93  \n",
       "5        0.89  0.98       0.95  \n",
       "5        0.79  0.97       0.90  \n",
       "6        0.87  0.98       0.93  \n",
       "6        0.89  0.99       0.95  \n",
       "6        0.79  0.97       0.90  \n",
       "7        0.87  0.98       0.93  \n",
       "7        0.89  0.98       0.95  \n",
       "7        0.79  0.97       0.90  \n",
       "8        0.87  0.98       0.93  \n",
       "8        0.89  0.98       0.95  \n",
       "8        0.79  0.97       0.90  \n",
       "9        0.87  0.98       0.93  \n",
       "9        0.89  0.98       0.95  \n",
       "9        0.78  0.97       0.90  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_multiclass = df_results[df_results.Approach == 'multiclass'].set_index('Seed')\n",
    "\n",
    "for lbl in lbl_multiclass.classes_:\n",
    "    #df_results_multiclass[lbl+'_P'] = df_results_multiclass['All Metrics'].apply(lambda x:x[lbl]['precision'])\n",
    "    #df_results_multiclass[lbl+'_R'] = df_results_multiclass['All Metrics'].apply(lambda x:x[lbl]['recall'])\n",
    "    df_results_multiclass[lbl+'_F1'] = df_results_multiclass['All Metrics'].apply(lambda x:x[lbl]['f1-score'])\n",
    "\n",
    "df_results_multiclass.drop(columns=['All Metrics'], inplace=True)\n",
    "df_results_multiclass.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e893fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>PositiveAndNegativeMetrics</th>\n",
       "      <th>AC_F1</th>\n",
       "      <th>AJ_F1</th>\n",
       "      <th>CRED_F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>PA_PIP_F1</th>\n",
       "      <th>Confusion_matrix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.826347</td>\n",
       "      <td>0.888013</td>\n",
       "      <td>0.985067</td>\n",
       "      <td>0.949957</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.882213</td>\n",
       "      <td>0.984852</td>\n",
       "      <td>0.949936</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.886614</td>\n",
       "      <td>0.984993</td>\n",
       "      <td>0.949530</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>[107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.888713</td>\n",
       "      <td>0.984890</td>\n",
       "      <td>0.949261</td>\n",
       "      <td>[107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.826347</td>\n",
       "      <td>0.890637</td>\n",
       "      <td>0.985135</td>\n",
       "      <td>0.949797</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.885400</td>\n",
       "      <td>0.984735</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.840237</td>\n",
       "      <td>0.887836</td>\n",
       "      <td>0.985140</td>\n",
       "      <td>0.949957</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.8722</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.826347</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.984923</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.984779</td>\n",
       "      <td>0.948449</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.840237</td>\n",
       "      <td>0.885556</td>\n",
       "      <td>0.984672</td>\n",
       "      <td>0.947707</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model    Approach  Accuracy  Precision  Recall      F1  \\\n",
       "Seed                                                           \n",
       "0     SVC()  multiclass    0.9754     0.9673  0.8738  0.9162   \n",
       "1     SVC()  multiclass    0.9751     0.9693  0.8727  0.9165   \n",
       "2     SVC()  multiclass    0.9753     0.9694  0.8763  0.9187   \n",
       "3     SVC()  multiclass    0.9751     0.9674  0.8681  0.9129   \n",
       "4     SVC()  multiclass    0.9756     0.9672  0.8748  0.9167   \n",
       "5     SVC()  multiclass    0.9749     0.9679  0.8738  0.9164   \n",
       "6     SVC()  multiclass    0.9756     0.9680  0.8777  0.9190   \n",
       "7     SVC()  multiclass    0.9752     0.9664  0.8722  0.9150   \n",
       "8     SVC()  multiclass    0.9750     0.9674  0.8733  0.9161   \n",
       "9     SVC()  multiclass    0.9748     0.9671  0.8766  0.9180   \n",
       "\n",
       "                             PositiveAndNegativeMetrics     AC_F1     AJ_F1  \\\n",
       "Seed                                                                          \n",
       "0     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...  0.931624  0.826347   \n",
       "1     [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...  0.927039  0.838323   \n",
       "2     [108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...  0.927039  0.845238   \n",
       "3     [107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...  0.922414  0.819277   \n",
       "4     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...  0.931624  0.826347   \n",
       "5     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...  0.931624  0.831325   \n",
       "6     [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...  0.931624  0.840237   \n",
       "7     [108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...  0.927039  0.826347   \n",
       "8     [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...  0.927039  0.833333   \n",
       "9     [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...  0.931624  0.840237   \n",
       "\n",
       "       CRED_F1      N_F1  PA_PIP_F1  \\\n",
       "Seed                                  \n",
       "0     0.888013  0.985067   0.949957   \n",
       "1     0.882213  0.984852   0.949936   \n",
       "2     0.886614  0.984993   0.949530   \n",
       "3     0.888713  0.984890   0.949261   \n",
       "4     0.890637  0.985135   0.949797   \n",
       "5     0.885400  0.984735   0.948718   \n",
       "6     0.887836  0.985140   0.949957   \n",
       "7     0.886792  0.984923   0.949690   \n",
       "8     0.886957  0.984779   0.948449   \n",
       "9     0.885556  0.984672   0.947707   \n",
       "\n",
       "                                       Confusion_matrix  \n",
       "Seed                                                     \n",
       "0     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...  \n",
       "1     [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...  \n",
       "2     [108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...  \n",
       "3     [107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...  \n",
       "4     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...  \n",
       "5     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...  \n",
       "6     [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...  \n",
       "7     [108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...  \n",
       "8     [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...  \n",
       "9     [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_multiclass_svc = df_results_multiclass[df_results_multiclass.Model == 'SVC()']\n",
    "df_results_multiclass_svc['Confusion_matrix'] = df_results_multiclass_svc.PositiveAndNegativeMetrics\n",
    "df_results_multiclass_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9c9c3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AC_F1</th>\n",
       "      <th>AJ_F1</th>\n",
       "      <th>CRED_F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>PA_PIP_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.9493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  Precision  Recall      F1   AC_F1   AJ_F1  CRED_F1    N_F1  \\\n",
       "mean    0.9752     0.9677  0.8739  0.9166  0.9289  0.8327   0.8869  0.9849   \n",
       "std     0.0003     0.0010  0.0027  0.0018  0.0032  0.0082   0.0022  0.0002   \n",
       "\n",
       "      PA_PIP_F1  \n",
       "mean     0.9493  \n",
       "std      0.0008  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_multiclass[df_results_multiclass.Model == 'SVC()'].describe()[1:3].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38debd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AC_F1</th>\n",
       "      <th>AJ_F1</th>\n",
       "      <th>CRED_F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>PA_PIP_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  Precision  Recall    F1  AC_F1  AJ_F1  CRED_F1  N_F1  \\\n",
       "mean      0.94       0.93    0.59  0.63   0.44   0.06     0.79  0.97   \n",
       "std       0.00       0.00    0.00  0.00   0.01   0.01     0.00  0.00   \n",
       "\n",
       "      PA_PIP_F1  \n",
       "mean        0.9  \n",
       "std         0.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_multiclass[df_results_multiclass.Model == 'MultinomialNB()'].describe()[1:3].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2d9a188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AC_F1</th>\n",
       "      <th>AJ_F1</th>\n",
       "      <th>CRED_F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>PA_PIP_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  Precision  Recall   F1  AC_F1  AJ_F1  CRED_F1  N_F1  PA_PIP_F1\n",
       "mean      0.97       0.96    0.84  0.9   0.89   0.81     0.87  0.98       0.93\n",
       "std       0.00       0.00    0.00  0.0   0.00   0.01     0.00  0.00       0.00"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_multiclass[df_results_multiclass.Model == 'LogisticRegression()'].describe()[1:3].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81208eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>AJ</th>\n",
       "      <th>CRED</th>\n",
       "      <th>N</th>\n",
       "      <th>PA_PIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>108.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRED</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>562.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>14.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>120.5</td>\n",
       "      <td>13554.5</td>\n",
       "      <td>160.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA_PIP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.8</td>\n",
       "      <td>2218.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AC    AJ   CRED        N  PA_PIP\n",
       "AC      108.4   1.0    0.0      1.0     0.0\n",
       "AJ        0.0  69.7    0.0      3.7     0.0\n",
       "CRED      0.0   0.0  562.5     19.0     3.0\n",
       "N        14.6  23.3  120.5  13554.5   160.2\n",
       "PA_PIP    0.0   0.0    1.0     72.8  2218.8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cm(df_results_multiclass_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25bbacba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>PositiveAndNegativeMetrics</th>\n",
       "      <th>AC_F1</th>\n",
       "      <th>AJ_F1</th>\n",
       "      <th>CRED_F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>PA_PIP_F1</th>\n",
       "      <th>Confusion_matrix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 65, 0, 28, 0, 0, 0, 554, ...</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.797546</td>\n",
       "      <td>0.870385</td>\n",
       "      <td>0.980725</td>\n",
       "      <td>0.931960</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 65, 0, 28, 0, 0, 0, 554, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>[98, 0, 0, 25, 0, 1, 65, 0, 28, 0, 0, 0, 553, ...</td>\n",
       "      <td>0.878924</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.872240</td>\n",
       "      <td>0.980587</td>\n",
       "      <td>0.930412</td>\n",
       "      <td>[98, 0, 0, 25, 0, 1, 65, 0, 28, 0, 0, 0, 553, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.871956</td>\n",
       "      <td>0.980836</td>\n",
       "      <td>0.931271</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.8434</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 554, ...</td>\n",
       "      <td>0.883929</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.871755</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.932072</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 554, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 557, ...</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.873725</td>\n",
       "      <td>0.980865</td>\n",
       "      <td>0.931389</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 557, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 555, ...</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.980842</td>\n",
       "      <td>0.930782</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 555, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 556,...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.872841</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.931101</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 556,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.8449</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 551, ...</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.869085</td>\n",
       "      <td>0.980762</td>\n",
       "      <td>0.931789</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 551, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.8954</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.871956</td>\n",
       "      <td>0.980616</td>\n",
       "      <td>0.930442</td>\n",
       "      <td>[100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>0.8382</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 64, 0, 29, 0, 0, 0, 553, ...</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.873618</td>\n",
       "      <td>0.980559</td>\n",
       "      <td>0.929632</td>\n",
       "      <td>[99, 0, 0, 24, 0, 1, 64, 0, 29, 0, 0, 0, 553, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model    Approach  Accuracy  Precision  Recall      F1  \\\n",
       "Seed                                                                          \n",
       "0     LogisticRegression()  multiclass    0.9683     0.9577  0.8415  0.8929   \n",
       "1     LogisticRegression()  multiclass    0.9681     0.9614  0.8392  0.8929   \n",
       "2     LogisticRegression()  multiclass    0.9685     0.9629  0.8453  0.8973   \n",
       "3     LogisticRegression()  multiclass    0.9686     0.9615  0.8434  0.8957   \n",
       "4     LogisticRegression()  multiclass    0.9686     0.9601  0.8467  0.8972   \n",
       "5     LogisticRegression()  multiclass    0.9685     0.9638  0.8435  0.8967   \n",
       "6     LogisticRegression()  multiclass    0.9685     0.9627  0.8457  0.8975   \n",
       "7     LogisticRegression()  multiclass    0.9684     0.9604  0.8449  0.8963   \n",
       "8     LogisticRegression()  multiclass    0.9682     0.9579  0.8451  0.8954   \n",
       "9     LogisticRegression()  multiclass    0.9681     0.9612  0.8382  0.8924   \n",
       "\n",
       "                             PositiveAndNegativeMetrics     AC_F1     AJ_F1  \\\n",
       "Seed                                                                          \n",
       "0     [99, 0, 0, 24, 0, 1, 65, 0, 28, 0, 0, 0, 554, ...  0.883929  0.797546   \n",
       "1     [98, 0, 0, 25, 0, 1, 65, 0, 28, 0, 0, 0, 553, ...  0.878924  0.802469   \n",
       "2     [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...  0.892857  0.809816   \n",
       "3     [99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 554, ...  0.883929  0.809816   \n",
       "4     [99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 557, ...  0.887892  0.812121   \n",
       "5     [99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 555, ...  0.887892  0.809816   \n",
       "6     [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 556,...  0.892857  0.809816   \n",
       "7     [99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 551, ...  0.887892  0.812121   \n",
       "8     [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...  0.888889  0.804878   \n",
       "9     [99, 0, 0, 24, 0, 1, 64, 0, 29, 0, 0, 0, 553, ...  0.887892  0.790123   \n",
       "\n",
       "       CRED_F1      N_F1  PA_PIP_F1  \\\n",
       "Seed                                  \n",
       "0     0.870385  0.980725   0.931960   \n",
       "1     0.872240  0.980587   0.930412   \n",
       "2     0.871956  0.980836   0.931271   \n",
       "3     0.871755  0.980913   0.932072   \n",
       "4     0.873725  0.980865   0.931389   \n",
       "5     0.874016  0.980842   0.930782   \n",
       "6     0.872841  0.980833   0.931101   \n",
       "7     0.869085  0.980762   0.931789   \n",
       "8     0.871956  0.980616   0.930442   \n",
       "9     0.873618  0.980559   0.929632   \n",
       "\n",
       "                                       Confusion_matrix  \n",
       "Seed                                                     \n",
       "0     [99, 0, 0, 24, 0, 1, 65, 0, 28, 0, 0, 0, 554, ...  \n",
       "1     [98, 0, 0, 25, 0, 1, 65, 0, 28, 0, 0, 0, 553, ...  \n",
       "2     [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...  \n",
       "3     [99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 554, ...  \n",
       "4     [99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 557, ...  \n",
       "5     [99, 0, 0, 24, 0, 1, 66, 0, 27, 0, 0, 0, 555, ...  \n",
       "6     [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 556,...  \n",
       "7     [99, 0, 0, 24, 0, 1, 67, 0, 26, 0, 0, 0, 551, ...  \n",
       "8     [100, 0, 0, 23, 0, 1, 66, 0, 27, 0, 0, 0, 555,...  \n",
       "9     [99, 0, 0, 24, 0, 1, 64, 0, 29, 0, 0, 0, 553, ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_multiclass_lr = df_results_multiclass[df_results_multiclass.Model == 'LogisticRegression()']\n",
    "df_results_multiclass_lr['Confusion_matrix'] = df_results_multiclass_lr.PositiveAndNegativeMetrics\n",
    "df_results_multiclass_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22da428c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>AJ</th>\n",
       "      <th>CRED</th>\n",
       "      <th>N</th>\n",
       "      <th>PA_PIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>99.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>65.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRED</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>554.3</td>\n",
       "      <td>29.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>23.8</td>\n",
       "      <td>27.2</td>\n",
       "      <td>128.7</td>\n",
       "      <td>13511.6</td>\n",
       "      <td>211.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA_PIP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.7</td>\n",
       "      <td>2167.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AC    AJ   CRED        N  PA_PIP\n",
       "AC      99.2   1.0    0.0      0.4     0.0\n",
       "AJ       0.0  65.8    0.0      3.5     0.0\n",
       "CRED     0.0   0.0  554.3     29.8     3.0\n",
       "N       23.8  27.2  128.7  13511.6   211.2\n",
       "PA_PIP   0.0   0.0    1.0    105.7  2167.8"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cm(df_results_multiclass_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32edeb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>PositiveAndNegativeMetrics</th>\n",
       "      <th>AC_F1</th>\n",
       "      <th>AJ_F1</th>\n",
       "      <th>CRED_F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>PA_PIP_F1</th>\n",
       "      <th>Confusion_matrix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.9305</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6269</td>\n",
       "      <td>[32, 0, 0, 91, 0, 0, 3, 1, 90, 0, 0, 0, 525, 1...</td>\n",
       "      <td>0.412903</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.793051</td>\n",
       "      <td>0.965656</td>\n",
       "      <td>0.900828</td>\n",
       "      <td>[32, 0, 0, 91, 0, 0, 3, 1, 90, 0, 0, 0, 525, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9303</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...</td>\n",
       "      <td>0.433121</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.789354</td>\n",
       "      <td>0.965220</td>\n",
       "      <td>0.898709</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...</td>\n",
       "      <td>0.443038</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.786364</td>\n",
       "      <td>0.965626</td>\n",
       "      <td>0.901556</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>[33, 0, 0, 90, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.793338</td>\n",
       "      <td>0.965222</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>[33, 0, 0, 90, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>0.6268</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 2, 1, 91, 0, 0, 0, 525, 1...</td>\n",
       "      <td>0.433121</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.793051</td>\n",
       "      <td>0.965568</td>\n",
       "      <td>0.900443</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 2, 1, 91, 0, 0, 0, 525, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>0.6302</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 518, 1...</td>\n",
       "      <td>0.433121</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.789033</td>\n",
       "      <td>0.965631</td>\n",
       "      <td>0.901232</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 518, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9439</td>\n",
       "      <td>0.9294</td>\n",
       "      <td>0.5942</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...</td>\n",
       "      <td>0.433121</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.786687</td>\n",
       "      <td>0.965404</td>\n",
       "      <td>0.900566</td>\n",
       "      <td>[34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>0.5972</td>\n",
       "      <td>0.6327</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...</td>\n",
       "      <td>0.443038</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.792738</td>\n",
       "      <td>0.965613</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.9297</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...</td>\n",
       "      <td>0.443038</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.787282</td>\n",
       "      <td>0.965507</td>\n",
       "      <td>0.900868</td>\n",
       "      <td>[35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>0.5967</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>[36, 0, 0, 87, 0, 0, 3, 1, 90, 0, 0, 0, 516, 1...</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.784791</td>\n",
       "      <td>0.965548</td>\n",
       "      <td>0.901312</td>\n",
       "      <td>[36, 0, 0, 87, 0, 0, 3, 1, 90, 0, 0, 0, 516, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    Approach  Accuracy  Precision  Recall      F1  \\\n",
       "Seed                                                                     \n",
       "0     MultinomialNB()  multiclass    0.9443     0.9305  0.5926  0.6269   \n",
       "1     MultinomialNB()  multiclass    0.9436     0.9303  0.5937  0.6297   \n",
       "2     MultinomialNB()  multiclass    0.9443     0.9299  0.5957  0.6317   \n",
       "3     MultinomialNB()  multiclass    0.9436     0.9304  0.5932  0.6283   \n",
       "4     MultinomialNB()  multiclass    0.9442     0.9302  0.5939  0.6268   \n",
       "5     MultinomialNB()  multiclass    0.9443     0.9312  0.5939  0.6302   \n",
       "6     MultinomialNB()  multiclass    0.9439     0.9294  0.5942  0.6295   \n",
       "7     MultinomialNB()  multiclass    0.9443     0.9306  0.5972  0.6327   \n",
       "8     MultinomialNB()  multiclass    0.9441     0.9297  0.5960  0.6317   \n",
       "9     MultinomialNB()  multiclass    0.9441     0.9299  0.5967  0.6333   \n",
       "\n",
       "                             PositiveAndNegativeMetrics     AC_F1     AJ_F1  \\\n",
       "Seed                                                                          \n",
       "0     [32, 0, 0, 91, 0, 0, 3, 1, 90, 0, 0, 0, 525, 1...  0.412903  0.061856   \n",
       "1     [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...  0.433121  0.061856   \n",
       "2     [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...  0.443038  0.061856   \n",
       "3     [33, 0, 0, 90, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...  0.423077  0.061856   \n",
       "4     [34, 0, 0, 89, 0, 0, 2, 1, 91, 0, 0, 0, 525, 1...  0.433121  0.041667   \n",
       "5     [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 518, 1...  0.433121  0.061856   \n",
       "6     [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...  0.433121  0.061856   \n",
       "7     [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...  0.443038  0.061856   \n",
       "8     [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...  0.443038  0.061856   \n",
       "9     [36, 0, 0, 87, 0, 0, 3, 1, 90, 0, 0, 0, 516, 1...  0.452830  0.061856   \n",
       "\n",
       "       CRED_F1      N_F1  PA_PIP_F1  \\\n",
       "Seed                                  \n",
       "0     0.793051  0.965656   0.900828   \n",
       "1     0.789354  0.965220   0.898709   \n",
       "2     0.786364  0.965626   0.901556   \n",
       "3     0.793338  0.965222   0.897959   \n",
       "4     0.793051  0.965568   0.900443   \n",
       "5     0.789033  0.965631   0.901232   \n",
       "6     0.786687  0.965404   0.900566   \n",
       "7     0.792738  0.965613   0.900505   \n",
       "8     0.787282  0.965507   0.900868   \n",
       "9     0.784791  0.965548   0.901312   \n",
       "\n",
       "                                       Confusion_matrix  \n",
       "Seed                                                     \n",
       "0     [32, 0, 0, 91, 0, 0, 3, 1, 90, 0, 0, 0, 525, 1...  \n",
       "1     [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...  \n",
       "2     [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 519, 1...  \n",
       "3     [33, 0, 0, 90, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...  \n",
       "4     [34, 0, 0, 89, 0, 0, 2, 1, 91, 0, 0, 0, 525, 1...  \n",
       "5     [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 518, 1...  \n",
       "6     [34, 0, 0, 89, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...  \n",
       "7     [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 524, 1...  \n",
       "8     [35, 0, 0, 88, 0, 0, 3, 1, 90, 0, 0, 0, 520, 1...  \n",
       "9     [36, 0, 0, 87, 0, 0, 3, 1, 90, 0, 0, 0, 516, 1...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_multiclass_nb = df_results_multiclass[df_results_multiclass.Model == 'MultinomialNB()']\n",
    "df_results_multiclass_nb['Confusion_matrix'] = df_results_multiclass_nb.PositiveAndNegativeMetrics\n",
    "df_results_multiclass_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90a42487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>AJ</th>\n",
       "      <th>CRED</th>\n",
       "      <th>N</th>\n",
       "      <th>PA_PIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>34.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRED</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>112.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>88.8</td>\n",
       "      <td>90.1</td>\n",
       "      <td>161.2</td>\n",
       "      <td>13199.1</td>\n",
       "      <td>151.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA_PIP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>339.2</td>\n",
       "      <td>2229.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AC    AJ   CRED        N  PA_PIP\n",
       "AC      34.2   0.0    0.0      0.0     0.0\n",
       "AJ       0.0   2.9    0.0      0.0     0.0\n",
       "CRED     0.0   1.0  521.0    112.7     1.0\n",
       "N       88.8  90.1  161.2  13199.1   151.3\n",
       "PA_PIP   0.0   0.0    1.8    339.2  2229.7"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cm(df_results_multiclass_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3c65515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results_multiclass_svc[['AC_R', 'AJ_R', 'CRED_R', 'N_R', 'PA_PIP_R']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49d82c7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(10, 7)) \n",
    "plt.ylabel('F1')\n",
    "plt.title('Experimento Multi-classe - E2')\n",
    "plt.plot(label_x.X, df_results_multiclass[df_results_multiclass.Model == 'SVC()'].F1, marker=\".\",c='red', label='SVC')\n",
    "plt.plot(label_x.X, df_results_multiclass[df_results_multiclass.Model == 'LogisticRegression()'].F1, marker=\".\",c='green', label='LogisticRegression')\n",
    "plt.plot(label_x.X, df_results_multiclass[df_results_multiclass.Model == 'MultinomialNB()'].F1, marker=\".\",c='blue', label='MultinomialNB')\n",
    "plt.grid(True)\n",
    "plt.legend(loc=7)\n",
    "f.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b7c6b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Approach</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>PositiveAndNegativeMetrics</th>\n",
       "      <th>AC_F1</th>\n",
       "      <th>AJ_F1</th>\n",
       "      <th>CRED_F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>PA_PIP_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>[107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.888713</td>\n",
       "      <td>0.984890</td>\n",
       "      <td>0.949261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>0.8722</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.826347</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.984923</td>\n",
       "      <td>0.949690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.984779</td>\n",
       "      <td>0.948449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.826347</td>\n",
       "      <td>0.888013</td>\n",
       "      <td>0.985067</td>\n",
       "      <td>0.949957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.885400</td>\n",
       "      <td>0.984735</td>\n",
       "      <td>0.948718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.882213</td>\n",
       "      <td>0.984852</td>\n",
       "      <td>0.949936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.826347</td>\n",
       "      <td>0.890637</td>\n",
       "      <td>0.985135</td>\n",
       "      <td>0.949797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.840237</td>\n",
       "      <td>0.885556</td>\n",
       "      <td>0.984672</td>\n",
       "      <td>0.947707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>[108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.886614</td>\n",
       "      <td>0.984993</td>\n",
       "      <td>0.949530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>multiclass</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>[109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.840237</td>\n",
       "      <td>0.887836</td>\n",
       "      <td>0.985140</td>\n",
       "      <td>0.949957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model    Approach  Accuracy  Precision  Recall      F1  \\\n",
       "Seed                                                           \n",
       "3     SVC()  multiclass    0.9751     0.9674  0.8681  0.9129   \n",
       "7     SVC()  multiclass    0.9752     0.9664  0.8722  0.9150   \n",
       "8     SVC()  multiclass    0.9750     0.9674  0.8733  0.9161   \n",
       "0     SVC()  multiclass    0.9754     0.9673  0.8738  0.9162   \n",
       "5     SVC()  multiclass    0.9749     0.9679  0.8738  0.9164   \n",
       "1     SVC()  multiclass    0.9751     0.9693  0.8727  0.9165   \n",
       "4     SVC()  multiclass    0.9756     0.9672  0.8748  0.9167   \n",
       "9     SVC()  multiclass    0.9748     0.9671  0.8766  0.9180   \n",
       "2     SVC()  multiclass    0.9753     0.9694  0.8763  0.9187   \n",
       "6     SVC()  multiclass    0.9756     0.9680  0.8777  0.9190   \n",
       "\n",
       "                             PositiveAndNegativeMetrics     AC_F1     AJ_F1  \\\n",
       "Seed                                                                          \n",
       "3     [107, 0, 0, 16, 0, 1, 68, 0, 25, 0, 0, 0, 563,...  0.922414  0.819277   \n",
       "7     [108, 0, 0, 15, 0, 1, 69, 0, 24, 0, 0, 0, 564,...  0.927039  0.826347   \n",
       "8     [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 561,...  0.927039  0.833333   \n",
       "0     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 563,...  0.931624  0.826347   \n",
       "5     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 564,...  0.931624  0.831325   \n",
       "1     [108, 0, 0, 15, 0, 1, 70, 0, 23, 0, 0, 0, 558,...  0.927039  0.838323   \n",
       "4     [109, 0, 0, 14, 0, 1, 69, 0, 24, 0, 0, 0, 566,...  0.931624  0.826347   \n",
       "9     [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 561,...  0.931624  0.840237   \n",
       "2     [108, 0, 0, 15, 0, 1, 71, 0, 22, 0, 0, 0, 563,...  0.927039  0.845238   \n",
       "6     [109, 0, 0, 14, 0, 1, 71, 0, 22, 0, 0, 0, 562,...  0.931624  0.840237   \n",
       "\n",
       "       CRED_F1      N_F1  PA_PIP_F1  \n",
       "Seed                                 \n",
       "3     0.888713  0.984890   0.949261  \n",
       "7     0.886792  0.984923   0.949690  \n",
       "8     0.886957  0.984779   0.948449  \n",
       "0     0.888013  0.985067   0.949957  \n",
       "5     0.885400  0.984735   0.948718  \n",
       "1     0.882213  0.984852   0.949936  \n",
       "4     0.890637  0.985135   0.949797  \n",
       "9     0.885556  0.984672   0.947707  \n",
       "2     0.886614  0.984993   0.949530  \n",
       "6     0.887836  0.985140   0.949957  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_multiclass_svc = df_results_multiclass[ df_results_multiclass.Model == \"SVC()\"]\n",
    "df_results_multiclass_svc.sort_values(by=['F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e8f10b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(10, 7)) \n",
    "plt.ylabel('F1')\n",
    "plt.plot(label_x.X, df_results_multiclass_svc.AC_F1, marker=\".\",c='blue', label='F1 da classe AC')\n",
    "plt.plot(label_x.X, df_results_multiclass_svc.AJ_F1, marker=\".\",c='brown', label='F1 da classe AJ')\n",
    "plt.plot(label_x.X, df_results_multiclass_svc.CRED_F1, marker=\".\",c='black', label='F1 da classe CRED')\n",
    "plt.plot(label_x.X, df_results_multiclass_svc.N_F1, marker=\".\",c='red', label='F1 da classe N')\n",
    "plt.plot(label_x.X, df_results_multiclass_svc.PA_PIP_F1, marker=\".\",c='green', label='F1 da classe PA_PIP')\n",
    "plt.grid(True)\n",
    "plt.legend(bbox_to_anchor = (1.01,0.8))\n",
    "plt.yticks(np.arange(0.8, 1.01, 0.01))\n",
    "f.autofmt_xdate()\n",
    "plt.title('Desempenho do F1 por classe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdec7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "media = df_results_multiclass_svc[['AC_F1', 'AJ_F1','CRED_F1','N_F1','PA_PIP_F1']].mean().round(2)\n",
    "std = df_results_multiclass_svc[['AC_F1', 'AJ_F1','CRED_F1','N_F1','PA_PIP_F1']].std().round(4)\n",
    "minimo = df_results_multiclass_svc[['AC_F1', 'AJ_F1','CRED_F1','N_F1','PA_PIP_F1']].min().round(2)\n",
    "maximo = df_results_multiclass_svc[['AC_F1', 'AJ_F1','CRED_F1','N_F1','PA_PIP_F1']].max().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a5d27a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AC_F1        0.93\n",
       "AJ_F1        0.83\n",
       "CRED_F1      0.89\n",
       "N_F1         0.98\n",
       "PA_PIP_F1    0.95\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "381c9f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC_F1</th>\n",
       "      <th>AJ_F1</th>\n",
       "      <th>CRED_F1</th>\n",
       "      <th>N_F1</th>\n",
       "      <th>PA_PIP_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Média</th>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mínimo</th>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Máximo</th>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Desvio Padrão</th>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AC_F1   AJ_F1  CRED_F1    N_F1  PA_PIP_F1\n",
       "Média          0.9300  0.8300   0.8900  0.9800     0.9500\n",
       "Mínimo         0.9200  0.8200   0.8800  0.9800     0.9500\n",
       "Máximo         0.9300  0.8500   0.8900  0.9900     0.9500\n",
       "Desvio Padrão  0.0032  0.0082   0.0022  0.0002     0.0008"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([media, minimo, maximo, std], index=['Média', 'Mínimo', 'Máximo', 'Desvio Padrão'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
